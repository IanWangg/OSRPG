2021-07-02 23:28:50.061952 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 0 finished
-----------------------------  --------------
replay_buffer/size             2000
trainer/QF1 Loss                  0.903537
trainer/QF2 Loss                  0.902664
trainer/Policy Loss              -0.00583259
trainer/Q1 Predictions Mean      -0.000245239
trainer/Q1 Predictions Std        0.000310986
trainer/Q1 Predictions Max        0.00103076
trainer/Q1 Predictions Min       -0.00083014
trainer/Q2 Predictions Mean       0.000226224
trainer/Q2 Predictions Std        0.000168676
trainer/Q2 Predictions Max        0.000585807
trainer/Q2 Predictions Min       -0.000187801
trainer/Q Targets Mean            0.9386
trainer/Q Targets Std             0.148693
trainer/Q Targets Max             1.33331
trainer/Q Targets Min             0.471234
trainer/Bellman Errors 1 Mean     0.903537
trainer/Bellman Errors 1 Std      0.27793
trainer/Bellman Errors 1 Max      1.77665
trainer/Bellman Errors 1 Min      0.222277
trainer/Bellman Errors 2 Mean     0.902664
trainer/Bellman Errors 2 Std      0.277902
trainer/Bellman Errors 2 Max      1.77645
trainer/Bellman Errors 2 Min      0.221586
trainer/Policy Action Mean       -0.000526343
trainer/Policy Action Std         0.000314558
trainer/Policy Action Max         0.000198161
trainer/Policy Action Min        -0.0016303
exploration/num steps total    2000
exploration/num paths total      37
exploration/path length Mean     50
exploration/path length Std      16.6763
exploration/path length Max      86
exploration/path length Min      18
exploration/Rewards Mean          0.902526
exploration/Rewards Std           0.129815
exploration/Rewards Max           1.14946
exploration/Rewards Min           0.378668
exploration/Returns Mean         45.1263
exploration/Returns Std          15.8073
exploration/Returns Max          78.4415
exploration/Returns Min          17.3827
exploration/Actions Mean         -0.000932203
exploration/Actions Std           0.100811
exploration/Actions Max           0.387402
exploration/Actions Min          -0.328159
exploration/Num Paths            20
exploration/Average Returns      45.1263
evaluation/num steps total     4931
evaluation/num paths total       38
evaluation/path length Mean     129.763
evaluation/path length Std       14.1597
evaluation/path length Max      163
evaluation/path length Min      105
evaluation/Rewards Mean           0.964486
evaluation/Rewards Std            0.0594128
evaluation/Rewards Max            1.31428
evaluation/Rewards Min            0.692602
evaluation/Returns Mean         125.155
evaluation/Returns Std           18.1157
evaluation/Returns Max          176.743
evaluation/Returns Min           97.3207
evaluation/Actions Mean          -0.000459508
evaluation/Actions Std            0.000235574
evaluation/Actions Max           -6.81617e-05
evaluation/Actions Min           -0.00100813
evaluation/Num Paths             38
evaluation/Average Returns      125.155
time/data storing (s)             0.00336563
time/evaluation sampling (s)      1.83116
time/exploration sampling (s)     0.375927
time/logging (s)                  0.0147916
time/saving (s)                   0.00327923
time/training (s)                 3.69471
time/epoch (s)                    5.92324
time/total (s)                    7.73586
Epoch                             0
-----------------------------  --------------
2021-07-02 23:28:55.975606 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 1 finished
-----------------------------  --------------
replay_buffer/size             3000
trainer/QF1 Loss                  0.131665
trainer/QF2 Loss                  0.128587
trainer/Policy Loss              -2.60355
trainer/Q1 Predictions Mean       2.15078
trainer/Q1 Predictions Std        0.390553
trainer/Q1 Predictions Max        3.10148
trainer/Q1 Predictions Min        0.821322
trainer/Q2 Predictions Mean       2.32117
trainer/Q2 Predictions Std        0.324084
trainer/Q2 Predictions Max        3.09317
trainer/Q2 Predictions Min        0.803582
trainer/Q Targets Mean            2.23194
trainer/Q Targets Std             0.416734
trainer/Q Targets Max             3.00484
trainer/Q Targets Min             0.694914
trainer/Bellman Errors 1 Mean     0.131665
trainer/Bellman Errors 1 Std      0.284232
trainer/Bellman Errors 1 Max      1.49942
trainer/Bellman Errors 1 Min      3.70467e-06
trainer/Bellman Errors 2 Mean     0.128587
trainer/Bellman Errors 2 Std      0.656934
trainer/Bellman Errors 2 Max      4.57467
trainer/Bellman Errors 2 Min      8.31557e-08
trainer/Policy Action Mean        0.333363
trainer/Policy Action Std         0.942767
trainer/Policy Action Max         1
trainer/Policy Action Min        -1
exploration/num steps total    3000
exploration/num paths total     180
exploration/path length Mean      6.99301
exploration/path length Std       0.186859
exploration/path length Max       8
exploration/path length Min       5
exploration/Rewards Mean          0.840473
exploration/Rewards Std           0.102792
exploration/Rewards Max           1.03544
exploration/Rewards Min           0.662411
exploration/Returns Mean          5.87743
exploration/Returns Std           0.172075
exploration/Returns Max           7.04848
exploration/Returns Min           4.49783
exploration/Actions Mean          0.318669
exploration/Actions Std           0.907314
exploration/Actions Max           1
exploration/Actions Min          -1
exploration/Num Paths           143
exploration/Average Returns       5.87743
evaluation/num steps total     9929
evaluation/num paths total      752
evaluation/path length Mean       7
evaluation/path length Std        0
evaluation/path length Max        7
evaluation/path length Min        7
evaluation/Rewards Mean           0.833609
evaluation/Rewards Std            0.101428
evaluation/Rewards Max            1.03671
evaluation/Rewards Min            0.658554
evaluation/Returns Mean           5.83526
evaluation/Returns Std            0.0586799
evaluation/Returns Max            6.00879
evaluation/Returns Min            5.68699
evaluation/Actions Mean           0.333341
evaluation/Actions Std            0.942798
evaluation/Actions Max            1
evaluation/Actions Min           -1
evaluation/Num Paths            714
evaluation/Average Returns        5.83526
time/data storing (s)             0.00357768
time/evaluation sampling (s)      1.93735
time/exploration sampling (s)     0.395808
time/logging (s)                  0.0236757
time/saving (s)                   0.00343641
time/training (s)                 3.5542
time/epoch (s)                    5.91805
time/total (s)                   13.6578
Epoch                             1
-----------------------------  --------------
2021-07-02 23:29:01.880255 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 2 finished
-----------------------------  ---------------
replay_buffer/size              4000
trainer/QF1 Loss                   9.64042
trainer/QF2 Loss                   8.17561
trainer/Policy Loss               -8.14293
trainer/Q1 Predictions Mean        9.21682
trainer/Q1 Predictions Std         6.51433
trainer/Q1 Predictions Max        24.6054
trainer/Q1 Predictions Min         0.693095
trainer/Q2 Predictions Mean        9.00003
trainer/Q2 Predictions Std         6.25479
trainer/Q2 Predictions Max        22.8413
trainer/Q2 Predictions Min         0.650934
trainer/Q Targets Mean             7.8141
trainer/Q Targets Std              4.46846
trainer/Q Targets Max             18.256
trainer/Q Targets Min              0.67114
trainer/Bellman Errors 1 Mean      9.64042
trainer/Bellman Errors 1 Std      35.7721
trainer/Bellman Errors 1 Max     393.104
trainer/Bellman Errors 1 Min       1.27761e-05
trainer/Bellman Errors 2 Mean      8.17562
trainer/Bellman Errors 2 Std      34.9949
trainer/Bellman Errors 2 Max     387.01
trainer/Bellman Errors 2 Min       1.45885e-06
trainer/Policy Action Mean         0.999987
trainer/Policy Action Std          5.34543e-05
trainer/Policy Action Max          1
trainer/Policy Action Min          0.999566
exploration/num steps total     4000
exploration/num paths total      225
exploration/path length Mean      22.2222
exploration/path length Std        1.24524
exploration/path length Max       23
exploration/path length Min       15
exploration/Rewards Mean           1.75077
exploration/Rewards Std            0.464185
exploration/Rewards Max            2.43853
exploration/Rewards Min            1.00742
exploration/Returns Mean          38.9059
exploration/Returns Std            2.36696
exploration/Returns Max           40.5772
exploration/Returns Min           24.4901
exploration/Actions Mean           0.960594
exploration/Actions Std            0.057685
exploration/Actions Max            1
exploration/Actions Min            0.683636
exploration/Num Paths             45
exploration/Average Returns       38.9059
evaluation/num steps total     14919
evaluation/num paths total       978
evaluation/path length Mean       22.0796
evaluation/path length Std         0.566648
evaluation/path length Max        23
evaluation/path length Min        21
evaluation/Rewards Mean            1.75754
evaluation/Rewards Std             0.463405
evaluation/Rewards Max             2.41517
evaluation/Rewards Min             1.00567
evaluation/Returns Mean           38.806
evaluation/Returns Std             0.936477
evaluation/Returns Max            40.6451
evaluation/Returns Min            36.7153
evaluation/Actions Mean            0.999957
evaluation/Actions Std             8.99394e-05
evaluation/Actions Max             1
evaluation/Actions Min             0.999415
evaluation/Num Paths             226
evaluation/Average Returns        38.806
time/data storing (s)              0.00349633
time/evaluation sampling (s)       1.87286
time/exploration sampling (s)      0.389139
time/logging (s)                   0.0122403
time/saving (s)                    0.00346963
time/training (s)                  3.60624
time/epoch (s)                     5.88744
time/total (s)                    19.5504
Epoch                              2
-----------------------------  ---------------
2021-07-02 23:29:07.752298 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 3 finished
-----------------------------  ---------------
replay_buffer/size              5000
trainer/QF1 Loss                 360.744
trainer/QF2 Loss                 953.741
trainer/Policy Loss              -20.5222
trainer/Q1 Predictions Mean       25.3665
trainer/Q1 Predictions Std        31.69
trainer/Q1 Predictions Max       135.987
trainer/Q1 Predictions Min         0.692457
trainer/Q2 Predictions Mean       30.3289
trainer/Q2 Predictions Std        42.4797
trainer/Q2 Predictions Max       179.207
trainer/Q2 Predictions Min         0.641525
trainer/Q Targets Mean            19.36
trainer/Q Targets Std             17.1103
trainer/Q Targets Max             73.0396
trainer/Q Targets Min             -0.792444
trainer/Bellman Errors 1 Mean    360.744
trainer/Bellman Errors 1 Std    1231.95
trainer/Bellman Errors 1 Max    8381.25
trainer/Bellman Errors 1 Min       2.91289e-06
trainer/Bellman Errors 2 Mean    953.741
trainer/Bellman Errors 2 Std    3006.42
trainer/Bellman Errors 2 Max   18381.4
trainer/Bellman Errors 2 Min       4.11325e-05
trainer/Policy Action Mean         0.333333
trainer/Policy Action Std          0.942809
trainer/Policy Action Max          1
trainer/Policy Action Min         -1
exploration/num steps total     5000
exploration/num paths total      281
exploration/path length Mean      17.8571
exploration/path length Std        1.35526
exploration/path length Max       19
exploration/path length Min        8
exploration/Rewards Mean          -0.0602038
exploration/Rewards Std            0.784748
exploration/Rewards Max            1.07419
exploration/Rewards Min           -1.18279
exploration/Returns Mean          -1.07507
exploration/Returns Std            0.971882
exploration/Returns Max            5.85993
exploration/Returns Min           -1.74653
exploration/Actions Mean           0.320007
exploration/Actions Std            0.906883
exploration/Actions Max            1
exploration/Actions Min           -1
exploration/Num Paths             56
exploration/Average Returns       -1.07507
evaluation/num steps total     19909
evaluation/num paths total      1259
evaluation/path length Mean       17.758
evaluation/path length Std         0.42829
evaluation/path length Max        18
evaluation/path length Min        17
evaluation/Rewards Mean           -0.0796973
evaluation/Rewards Std             0.791914
evaluation/Rewards Max             1.08421
evaluation/Rewards Min            -1.18842
evaluation/Returns Mean           -1.41527
evaluation/Returns Std             0.307957
evaluation/Returns Max            -0.619576
evaluation/Returns Min            -1.97854
evaluation/Actions Mean            0.333333
evaluation/Actions Std             0.942809
evaluation/Actions Max             1
evaluation/Actions Min            -1
evaluation/Num Paths             281
evaluation/Average Returns        -1.41527
time/data storing (s)              0.00350362
time/evaluation sampling (s)       1.88708
time/exploration sampling (s)      0.387533
time/logging (s)                   0.0141519
time/saving (s)                    0.00344405
time/training (s)                  3.57407
time/epoch (s)                     5.86978
time/total (s)                    25.424
Epoch                              3
-----------------------------  ---------------
2021-07-02 23:29:13.616087 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 4 finished
-----------------------------  ---------------
replay_buffer/size              6000
trainer/QF1 Loss                 327.036
trainer/QF2 Loss                 367.47
trainer/Policy Loss              -70.724
trainer/Q1 Predictions Mean       47.553
trainer/Q1 Predictions Std        49.2711
trainer/Q1 Predictions Max       202.046
trainer/Q1 Predictions Min        -1.7012
trainer/Q2 Predictions Mean       47.3727
trainer/Q2 Predictions Std        49.1366
trainer/Q2 Predictions Max       202.689
trainer/Q2 Predictions Min        -1.06492
trainer/Q Targets Mean            45.0887
trainer/Q Targets Std             48.0655
trainer/Q Targets Max            205.041
trainer/Q Targets Min             -1.10254
trainer/Bellman Errors 1 Mean    327.036
trainer/Bellman Errors 1 Std    1364.59
trainer/Bellman Errors 1 Max   10955.3
trainer/Bellman Errors 1 Min       0.000389483
trainer/Bellman Errors 2 Mean    367.47
trainer/Bellman Errors 2 Std    1658.6
trainer/Bellman Errors 2 Max   17052.3
trainer/Bellman Errors 2 Min       2.6767e-07
trainer/Policy Action Mean        -0.216232
trainer/Policy Action Std          0.961341
trainer/Policy Action Max          1
trainer/Policy Action Min         -1
exploration/num steps total     6000
exploration/num paths total      360
exploration/path length Mean      12.6582
exploration/path length Std        0.524973
exploration/path length Max       13
exploration/path length Min       11
exploration/Rewards Mean           0.222585
exploration/Rewards Std            0.628077
exploration/Rewards Max            0.916033
exploration/Rewards Min           -1.0458
exploration/Returns Mean           2.81753
exploration/Returns Std            0.461962
exploration/Returns Max            3.86653
exploration/Returns Min            2.01748
exploration/Actions Mean          -0.336329
exploration/Actions Std            0.886055
exploration/Actions Max            1
exploration/Actions Min           -1
exploration/Num Paths             79
exploration/Average Returns        2.81753
evaluation/num steps total     24902
evaluation/num paths total      1654
evaluation/path length Mean       12.6405
evaluation/path length Std         0.479852
evaluation/path length Max        13
evaluation/path length Min        12
evaluation/Rewards Mean            0.194923
evaluation/Rewards Std             0.641448
evaluation/Rewards Max             0.900848
evaluation/Rewards Min            -1.05498
evaluation/Returns Mean            2.46393
evaluation/Returns Std             0.499417
evaluation/Returns Max             3.40634
evaluation/Returns Min             1.75432
evaluation/Actions Mean           -0.380022
evaluation/Actions Std             0.918487
evaluation/Actions Max             1
evaluation/Actions Min            -1
evaluation/Num Paths             395
evaluation/Average Returns         2.46393
time/data storing (s)              0.00349641
time/evaluation sampling (s)       1.89154
time/exploration sampling (s)      0.387204
time/logging (s)                   0.0188443
time/saving (s)                    0.00341587
time/training (s)                  3.56025
time/epoch (s)                     5.86475
time/total (s)                    31.2922
Epoch                              4
-----------------------------  ---------------
2021-07-02 23:29:19.484272 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 5 finished
-----------------------------  ---------------
replay_buffer/size              7000
trainer/QF1 Loss                 275.016
trainer/QF2 Loss                 316.423
trainer/Policy Loss              -94.963
trainer/Q1 Predictions Mean       70.0376
trainer/Q1 Predictions Std       105.372
trainer/Q1 Predictions Max       595.163
trainer/Q1 Predictions Min        -4.73133
trainer/Q2 Predictions Mean       69.3967
trainer/Q2 Predictions Std       103.996
trainer/Q2 Predictions Max       587.873
trainer/Q2 Predictions Min        -3.94033
trainer/Q Targets Mean            73.0163
trainer/Q Targets Std            110.065
trainer/Q Targets Max            607.615
trainer/Q Targets Min             -3.65218
trainer/Bellman Errors 1 Mean    275.016
trainer/Bellman Errors 1 Std    2123.7
trainer/Bellman Errors 1 Max   30699.1
trainer/Bellman Errors 1 Min       2.31772e-05
trainer/Bellman Errors 2 Mean    316.423
trainer/Bellman Errors 2 Std    2286.1
trainer/Bellman Errors 2 Max   32450.2
trainer/Bellman Errors 2 Min       1.14329e-05
trainer/Policy Action Mean         0.14584
trainer/Policy Action Std          0.989245
trainer/Policy Action Max          1
trainer/Policy Action Min         -1
exploration/num steps total     7000
exploration/num paths total      416
exploration/path length Mean      17.8571
exploration/path length Std        1.23098
exploration/path length Max       19
exploration/path length Min        9
exploration/Rewards Mean          -0.0599305
exploration/Rewards Std            0.784012
exploration/Rewards Max            1.07785
exploration/Rewards Min           -1.16229
exploration/Returns Mean          -1.07019
exploration/Returns Std            0.956877
exploration/Returns Max            5.74074
exploration/Returns Min           -1.78816
exploration/Actions Mean           0.294551
exploration/Actions Std            0.914289
exploration/Actions Max            1
exploration/Actions Min           -1
exploration/Num Paths             56
exploration/Average Returns       -1.07019
evaluation/num steps total     29895
evaluation/num paths total      1935
evaluation/path length Mean       17.7687
evaluation/path length Std         0.421674
evaluation/path length Max        18
evaluation/path length Min        17
evaluation/Rewards Mean           -0.0799897
evaluation/Rewards Std             0.792394
evaluation/Rewards Max             1.07993
evaluation/Rewards Min            -1.18228
evaluation/Returns Mean           -1.42131
evaluation/Returns Std             0.310577
evaluation/Returns Max            -0.648706
evaluation/Returns Min            -2.0144
evaluation/Actions Mean            0.304702
evaluation/Actions Std             0.952003
evaluation/Actions Max             1
evaluation/Actions Min            -1
evaluation/Num Paths             281
evaluation/Average Returns        -1.42131
time/data storing (s)              0.00352946
time/evaluation sampling (s)       1.87769
time/exploration sampling (s)      0.38415
time/logging (s)                   0.0137522
time/saving (s)                    0.00360497
time/training (s)                  3.57472
time/epoch (s)                     5.85745
time/total (s)                    37.1546
Epoch                              5
-----------------------------  ---------------
2021-07-02 23:29:25.348891 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 6 finished
-----------------------------  ----------------
replay_buffer/size               8000
trainer/QF1 Loss                 2600.09
trainer/QF2 Loss                 2578.45
trainer/Policy Loss              -167.715
trainer/Q1 Predictions Mean       123.73
trainer/Q1 Predictions Std        246.475
trainer/Q1 Predictions Max       1332.46
trainer/Q1 Predictions Min        -20.9308
trainer/Q2 Predictions Mean       124.192
trainer/Q2 Predictions Std        246.729
trainer/Q2 Predictions Max       1333.29
trainer/Q2 Predictions Min         -5.48968
trainer/Q Targets Mean            127.746
trainer/Q Targets Std             259.32
trainer/Q Targets Max            1364.42
trainer/Q Targets Min             -29.4195
trainer/Bellman Errors 1 Mean    2600.09
trainer/Bellman Errors 1 Std    19266.9
trainer/Bellman Errors 1 Max   194528
trainer/Bellman Errors 1 Min        0.000108295
trainer/Bellman Errors 2 Mean    2578.45
trainer/Bellman Errors 2 Std    18709.7
trainer/Bellman Errors 2 Max   182183
trainer/Bellman Errors 2 Min        0.00503783
trainer/Policy Action Mean          0.171893
trainer/Policy Action Std           0.985089
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total      8000
exploration/num paths total       472
exploration/path length Mean       17.8571
exploration/path length Std         0.832993
exploration/path length Max        19
exploration/path length Min        12
exploration/Rewards Mean           -0.0626152
exploration/Rewards Std             0.784196
exploration/Rewards Max             1.07815
exploration/Rewards Min            -1.177
exploration/Returns Mean           -1.11813
exploration/Returns Std             0.787894
exploration/Returns Max             4.42621
exploration/Returns Min            -1.7233
exploration/Actions Mean            0.296198
exploration/Actions Std             0.913099
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              56
exploration/Average Returns        -1.11813
evaluation/num steps total      34882
evaluation/num paths total       2216
evaluation/path length Mean        17.7473
evaluation/path length Std          0.434543
evaluation/path length Max         18
evaluation/path length Min         17
evaluation/Rewards Mean            -0.0794274
evaluation/Rewards Std              0.792994
evaluation/Rewards Max              1.08391
evaluation/Rewards Min             -1.19325
evaluation/Returns Mean            -1.40962
evaluation/Returns Std              0.326173
evaluation/Returns Max             -0.556735
evaluation/Returns Min             -2.09049
evaluation/Actions Mean             0.306608
evaluation/Actions Std              0.951489
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths              281
evaluation/Average Returns         -1.40962
time/data storing (s)               0.00348553
time/evaluation sampling (s)        1.87345
time/exploration sampling (s)       0.38443
time/logging (s)                    0.014158
time/saving (s)                     0.00373458
time/training (s)                   3.58215
time/epoch (s)                      5.86141
time/total (s)                     43.0193
Epoch                               6
-----------------------------  ----------------
2021-07-02 23:29:31.230211 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 7 finished
-----------------------------  ----------------
replay_buffer/size               9000
trainer/QF1 Loss                 1415.2
trainer/QF2 Loss                 4259.32
trainer/Policy Loss              -236.029
trainer/Q1 Predictions Mean       193.346
trainer/Q1 Predictions Std        450.01
trainer/Q1 Predictions Max       2465.48
trainer/Q1 Predictions Min        -11.6233
trainer/Q2 Predictions Mean       194.377
trainer/Q2 Predictions Std        442.921
trainer/Q2 Predictions Max       2413.79
trainer/Q2 Predictions Min         -6.96207
trainer/Q Targets Mean            189.566
trainer/Q Targets Std             453.74
trainer/Q Targets Max            2522.65
trainer/Q Targets Min             -32.1727
trainer/Bellman Errors 1 Mean    1415.2
trainer/Bellman Errors 1 Std    12294.3
trainer/Bellman Errors 1 Max   193933
trainer/Bellman Errors 1 Min        0.000376577
trainer/Bellman Errors 2 Mean    4259.32
trainer/Bellman Errors 2 Std    22234.5
trainer/Bellman Errors 2 Max   206471
trainer/Bellman Errors 2 Min        0.000163512
trainer/Policy Action Mean         -0.0324426
trainer/Policy Action Std           0.986523
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total      9000
exploration/num paths total       523
exploration/path length Mean       19.6078
exploration/path length Std         0.841996
exploration/path length Max        21
exploration/path length Min        16
exploration/Rewards Mean           -0.0515244
exploration/Rewards Std             0.598723
exploration/Rewards Max             1.06371
exploration/Rewards Min            -1.18718
exploration/Returns Mean           -1.01028
exploration/Returns Std             0.435812
exploration/Returns Max             1.10696
exploration/Returns Min            -1.76219
exploration/Actions Mean            0.145406
exploration/Actions Std             0.940821
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              51
exploration/Average Returns        -1.01028
evaluation/num steps total      39867
evaluation/num paths total       2474
evaluation/path length Mean        19.3217
evaluation/path length Std          0.768312
evaluation/path length Max         21
evaluation/path length Min         18
evaluation/Rewards Mean            -0.0666196
evaluation/Rewards Std              0.615758
evaluation/Rewards Max              1.06427
evaluation/Rewards Min             -1.22635
evaluation/Returns Mean            -1.2872
evaluation/Returns Std              0.328226
evaluation/Returns Max             -0.327198
evaluation/Returns Min             -1.97341
evaluation/Actions Mean             0.151479
evaluation/Actions Std              0.978599
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths              258
evaluation/Average Returns         -1.2872
time/data storing (s)               0.00349795
time/evaluation sampling (s)        1.87275
time/exploration sampling (s)       0.381501
time/logging (s)                    0.0146391
time/saving (s)                     0.00366297
time/training (s)                   3.60176
time/epoch (s)                      5.87781
time/total (s)                     48.9008
Epoch                               7
-----------------------------  ----------------
2021-07-02 23:29:37.566049 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 8 finished
-----------------------------  ----------------
replay_buffer/size              10000
trainer/QF1 Loss                20896.1
trainer/QF2 Loss                18943.1
trainer/Policy Loss              -346.053
trainer/Q1 Predictions Mean       311.24
trainer/Q1 Predictions Std        660.492
trainer/Q1 Predictions Max       4088.61
trainer/Q1 Predictions Min        -13.5051
trainer/Q2 Predictions Mean       311.744
trainer/Q2 Predictions Std        664.804
trainer/Q2 Predictions Max       4154.05
trainer/Q2 Predictions Min        -11.0367
trainer/Q Targets Mean            307.954
trainer/Q Targets Std             679.837
trainer/Q Targets Max            4221.9
trainer/Q Targets Min             -14.6084
trainer/Bellman Errors 1 Mean   20896.1
trainer/Bellman Errors 1 Std   167993
trainer/Bellman Errors 1 Max        1.9712e+06
trainer/Bellman Errors 1 Min        1.4771e-07
trainer/Bellman Errors 2 Mean   18943.1
trainer/Bellman Errors 2 Std   161533
trainer/Bellman Errors 2 Max        1.82164e+06
trainer/Bellman Errors 2 Min        0.00647121
trainer/Policy Action Mean         -0.209507
trainer/Policy Action Std           0.950155
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     10000
exploration/num paths total       627
exploration/path length Mean        9.61538
exploration/path length Std         0.669496
exploration/path length Max        11
exploration/path length Min         5
exploration/Rewards Mean            0.0746322
exploration/Rewards Std             0.631404
exploration/Rewards Max             0.973626
exploration/Rewards Min            -0.908405
exploration/Returns Mean            0.717618
exploration/Returns Std             0.386764
exploration/Returns Max             3.13098
exploration/Returns Min             0.131834
exploration/Actions Mean           -0.156979
exploration/Actions Std             0.933279
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths             104
exploration/Average Returns         0.717618
evaluation/num steps total      44866
evaluation/num paths total       3018
evaluation/path length Mean         9.18934
evaluation/path length Std          0.391777
evaluation/path length Max         10
evaluation/path length Min          9
evaluation/Rewards Mean             0.0692755
evaluation/Rewards Std              0.648313
evaluation/Rewards Max              0.964497
evaluation/Rewards Min             -0.952846
evaluation/Returns Mean             0.636596
evaluation/Returns Std              0.269652
evaluation/Returns Max              0.892191
evaluation/Returns Min             -0.0199768
evaluation/Actions Mean            -0.18903
evaluation/Actions Std              0.963945
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths              544
evaluation/Average Returns          0.636596
time/data storing (s)               0.00360371
time/evaluation sampling (s)        2.19023
time/exploration sampling (s)       0.406602
time/logging (s)                    0.022813
time/saving (s)                     0.00384362
time/training (s)                   3.71251
time/epoch (s)                      6.3396
time/total (s)                     55.2443
Epoch                               8
-----------------------------  ----------------
2021-07-02 23:29:43.885356 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 9 finished
-----------------------------  ----------------
replay_buffer/size              11000
trainer/QF1 Loss                 6709.99
trainer/QF2 Loss                 6088.54
trainer/Policy Loss              -615.121
trainer/Q1 Predictions Mean       484.354
trainer/Q1 Predictions Std       1129.43
trainer/Q1 Predictions Max       6760.35
trainer/Q1 Predictions Min        -17.2596
trainer/Q2 Predictions Mean       480.813
trainer/Q2 Predictions Std       1127.69
trainer/Q2 Predictions Max       6736.4
trainer/Q2 Predictions Min        -16.865
trainer/Q Targets Mean            475.148
trainer/Q Targets Std            1139.78
trainer/Q Targets Max            6861.24
trainer/Q Targets Min             -22.0307
trainer/Bellman Errors 1 Mean    6709.99
trainer/Bellman Errors 1 Std    38781.7
trainer/Bellman Errors 1 Max   356227
trainer/Bellman Errors 1 Min        0.00297239
trainer/Bellman Errors 2 Mean    6088.54
trainer/Bellman Errors 2 Std    37999.3
trainer/Bellman Errors 2 Max   435019
trainer/Bellman Errors 2 Min        0.000212097
trainer/Policy Action Mean         -0.311076
trainer/Policy Action Std           0.935299
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     11000
exploration/num paths total       738
exploration/path length Mean        9.00901
exploration/path length Std         0.164152
exploration/path length Max        10
exploration/path length Min         8
exploration/Rewards Mean            0.0715111
exploration/Rewards Std             0.703836
exploration/Rewards Max             0.979866
exploration/Rewards Min            -1.34058
exploration/Returns Mean            0.644244
exploration/Returns Std             0.230299
exploration/Returns Max             1.61238
exploration/Returns Min            -0.469782
exploration/Actions Mean           -0.320206
exploration/Actions Std             0.906441
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths             111
exploration/Average Returns         0.644244
evaluation/num steps total      49861
evaluation/num paths total       3573
evaluation/path length Mean         9
evaluation/path length Std          0
evaluation/path length Max          9
evaluation/path length Min          9
evaluation/Rewards Mean             0.0279844
evaluation/Rewards Std              0.731573
evaluation/Rewards Max              0.964666
evaluation/Rewards Min             -1.22767
evaluation/Returns Mean             0.25186
evaluation/Returns Std              0.112341
evaluation/Returns Max              0.506834
evaluation/Returns Min             -0.0452525
evaluation/Actions Mean            -0.333328
evaluation/Actions Std              0.942805
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths              555
evaluation/Average Returns          0.25186
time/data storing (s)               0.00367251
time/evaluation sampling (s)        2.06858
time/exploration sampling (s)       0.416206
time/logging (s)                    0.0146404
time/saving (s)                     0.00343294
time/training (s)                   3.79846
time/epoch (s)                      6.30499
time/total (s)                     61.5548
Epoch                               9
-----------------------------  ----------------
2021-07-02 23:29:49.813411 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 10 finished
-----------------------------  ----------------
replay_buffer/size              12000
trainer/QF1 Loss                 4307.63
trainer/QF2 Loss                 5145.2
trainer/Policy Loss              -843.453
trainer/Q1 Predictions Mean       748.133
trainer/Q1 Predictions Std       1975.68
trainer/Q1 Predictions Max      10869.4
trainer/Q1 Predictions Min        -28.6272
trainer/Q2 Predictions Mean       740.74
trainer/Q2 Predictions Std       1973.12
trainer/Q2 Predictions Max      10950.3
trainer/Q2 Predictions Min        -28.865
trainer/Q Targets Mean            745.519
trainer/Q Targets Std            1963.09
trainer/Q Targets Max           10873.3
trainer/Q Targets Min             -37.9722
trainer/Bellman Errors 1 Mean    4307.63
trainer/Bellman Errors 1 Std    27423.8
trainer/Bellman Errors 1 Max   355950
trainer/Bellman Errors 1 Min        0.00080377
trainer/Bellman Errors 2 Mean    5145.2
trainer/Bellman Errors 2 Std    27106.1
trainer/Bellman Errors 2 Max   262022
trainer/Bellman Errors 2 Min        0.000523411
trainer/Policy Action Mean         -0.173064
trainer/Policy Action Std           0.975386
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     12000
exploration/num paths total       849
exploration/path length Mean        9.00901
exploration/path length Std         0.164152
exploration/path length Max        10
exploration/path length Min         8
exploration/Rewards Mean            0.068786
exploration/Rewards Std             0.704128
exploration/Rewards Max             0.973229
exploration/Rewards Min            -1.36847
exploration/Returns Mean            0.619694
exploration/Returns Std             0.262813
exploration/Returns Max             1.87844
exploration/Returns Min            -0.424379
exploration/Actions Mean           -0.320981
exploration/Actions Std             0.908269
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths             111
exploration/Average Returns         0.619694
evaluation/num steps total      54856
evaluation/num paths total       4128
evaluation/path length Mean         9
evaluation/path length Std          0
evaluation/path length Max          9
evaluation/path length Min          9
evaluation/Rewards Mean             0.0280393
evaluation/Rewards Std              0.731223
evaluation/Rewards Max              0.965504
evaluation/Rewards Min             -1.22541
evaluation/Returns Mean             0.252354
evaluation/Returns Std              0.115266
evaluation/Returns Max              0.507862
evaluation/Returns Min             -0.0211372
evaluation/Actions Mean            -0.333326
evaluation/Actions Std              0.942804
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths              555
evaluation/Average Returns          0.252354
time/data storing (s)               0.00369325
time/evaluation sampling (s)        1.91523
time/exploration sampling (s)       0.397489
time/logging (s)                    0.0138134
time/saving (s)                     0.00471245
time/training (s)                   3.58825
time/epoch (s)                      5.92318
time/total (s)                     67.4816
Epoch                              10
-----------------------------  ----------------
2021-07-02 23:29:55.739352 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 11 finished
-----------------------------  ----------------
replay_buffer/size              13000
trainer/QF1 Loss               118006
trainer/QF2 Loss               125612
trainer/Policy Loss              -923.695
trainer/Q1 Predictions Mean       809.785
trainer/Q1 Predictions Std       2720.72
trainer/Q1 Predictions Max      16379.6
trainer/Q1 Predictions Min        -42.1131
trainer/Q2 Predictions Mean       813.563
trainer/Q2 Predictions Std       2729.47
trainer/Q2 Predictions Max      16407.8
trainer/Q2 Predictions Min        -38.706
trainer/Q Targets Mean            787.505
trainer/Q Targets Std            2720.29
trainer/Q Targets Max           16540.3
trainer/Q Targets Min             -41.2824
trainer/Bellman Errors 1 Mean  118006
trainer/Bellman Errors 1 Std        1.29226e+06
trainer/Bellman Errors 1 Max        1.6572e+07
trainer/Bellman Errors 1 Min        9.39016e-05
trainer/Bellman Errors 2 Mean  125612
trainer/Bellman Errors 2 Std        1.37653e+06
trainer/Bellman Errors 2 Max        1.74887e+07
trainer/Bellman Errors 2 Min        0.000395738
trainer/Policy Action Mean         -0.244233
trainer/Policy Action Std           0.966292
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     13000
exploration/num paths total       961
exploration/path length Mean        8.92857
exploration/path length Std         0.752547
exploration/path length Max         9
exploration/path length Min         1
exploration/Rewards Mean            0.0683045
exploration/Rewards Std             0.704221
exploration/Rewards Max             0.973581
exploration/Rewards Min            -1.19222
exploration/Returns Mean            0.609862
exploration/Returns Std             0.198537
exploration/Returns Max             1.00936
exploration/Returns Min             0.0943047
exploration/Actions Mean           -0.321124
exploration/Actions Std             0.908922
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths             112
exploration/Average Returns         0.609862
evaluation/num steps total      59851
evaluation/num paths total       4683
evaluation/path length Mean         9
evaluation/path length Std          0
evaluation/path length Max          9
evaluation/path length Min          9
evaluation/Rewards Mean             0.0269848
evaluation/Rewards Std              0.73116
evaluation/Rewards Max              0.964519
evaluation/Rewards Min             -1.22478
evaluation/Returns Mean             0.242863
evaluation/Returns Std              0.111633
evaluation/Returns Max              0.522599
evaluation/Returns Min             -0.0115451
evaluation/Actions Mean            -0.333327
evaluation/Actions Std              0.942804
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths              555
evaluation/Average Returns          0.242863
time/data storing (s)               0.00353421
time/evaluation sampling (s)        1.91207
time/exploration sampling (s)       0.397602
time/logging (s)                    0.013524
time/saving (s)                     0.00347827
time/training (s)                   3.59125
time/epoch (s)                      5.92145
time/total (s)                     73.4069
Epoch                              11
-----------------------------  ----------------
2021-07-02 23:30:01.577284 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 12 finished
-----------------------------  ----------------
replay_buffer/size              14000
trainer/QF1 Loss               313439
trainer/QF2 Loss               339500
trainer/Policy Loss             -1605.11
trainer/Q1 Predictions Mean      1120.99
trainer/Q1 Predictions Std       3523.2
trainer/Q1 Predictions Max      21867.3
trainer/Q1 Predictions Min       -829.339
trainer/Q2 Predictions Mean      1190.57
trainer/Q2 Predictions Std       3562.86
trainer/Q2 Predictions Max      21793.8
trainer/Q2 Predictions Min        -37.8657
trainer/Q Targets Mean           1174.33
trainer/Q Targets Std            3553.36
trainer/Q Targets Max           21957.6
trainer/Q Targets Min            -516.407
trainer/Bellman Errors 1 Mean  313439
trainer/Bellman Errors 1 Std        2.39638e+06
trainer/Bellman Errors 1 Max        3.2945e+07
trainer/Bellman Errors 1 Min        0.0100578
trainer/Bellman Errors 2 Mean  339500
trainer/Bellman Errors 2 Std        2.62878e+06
trainer/Bellman Errors 2 Max        3.66342e+07
trainer/Bellman Errors 2 Min        0.0435056
trainer/Policy Action Mean          0.572572
trainer/Policy Action Std           0.772953
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     14000
exploration/num paths total       977
exploration/path length Mean       62.5
exploration/path length Std         2.23607
exploration/path length Max        66
exploration/path length Min        55
exploration/Rewards Mean            1.45986
exploration/Rewards Std             0.320206
exploration/Rewards Max             2.02092
exploration/Rewards Min             0.637689
exploration/Returns Mean           91.2413
exploration/Returns Std             2.2628
exploration/Returns Max            96.4289
exploration/Returns Min            85.0819
exploration/Actions Mean            0.557431
exploration/Actions Std             0.689816
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              16
exploration/Average Returns        91.2413
evaluation/num steps total      64794
evaluation/num paths total       4761
evaluation/path length Mean        63.3718
evaluation/path length Std          1.13351
evaluation/path length Max         66
evaluation/path length Min         61
evaluation/Rewards Mean             1.45554
evaluation/Rewards Std              0.32763
evaluation/Rewards Max              2.03308
evaluation/Rewards Min              0.5898
evaluation/Returns Mean            92.2403
evaluation/Returns Std              1.5106
evaluation/Returns Max             96.0867
evaluation/Returns Min             88.7266
evaluation/Actions Mean             0.579682
evaluation/Actions Std              0.712859
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               78
evaluation/Average Returns         92.2403
time/data storing (s)               0.00343389
time/evaluation sampling (s)        1.86316
time/exploration sampling (s)       0.379465
time/logging (s)                    0.010084
time/saving (s)                     0.00350927
time/training (s)                   3.57124
time/epoch (s)                      5.83089
time/total (s)                     79.241
Epoch                              12
-----------------------------  ----------------
2021-07-02 23:30:07.320786 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 13 finished
-----------------------------  ----------------
replay_buffer/size              15000
trainer/QF1 Loss               200256
trainer/QF2 Loss               212254
trainer/Policy Loss             -2326.32
trainer/Q1 Predictions Mean      1682.93
trainer/Q1 Predictions Std       3944.12
trainer/Q1 Predictions Max      20548.2
trainer/Q1 Predictions Min      -1139.94
trainer/Q2 Predictions Mean      1685.14
trainer/Q2 Predictions Std       3912.36
trainer/Q2 Predictions Max      20309.4
trainer/Q2 Predictions Min        -61.4387
trainer/Q Targets Mean           1653.59
trainer/Q Targets Std            3897.28
trainer/Q Targets Max           20854.7
trainer/Q Targets Min            -987.48
trainer/Bellman Errors 1 Mean  200256
trainer/Bellman Errors 1 Std        1.32709e+06
trainer/Bellman Errors 1 Max        1.79661e+07
trainer/Bellman Errors 1 Min        0.00211719
trainer/Bellman Errors 2 Mean  212254
trainer/Bellman Errors 2 Std        1.2546e+06
trainer/Bellman Errors 2 Max        1.49077e+07
trainer/Bellman Errors 2 Min        0.0171881
trainer/Policy Action Mean          0.648269
trainer/Policy Action Std           0.721843
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     15000
exploration/num paths total       996
exploration/path length Mean       52.6316
exploration/path length Std         5.1115
exploration/path length Max        68
exploration/path length Min        46
exploration/Rewards Mean            1.62433
exploration/Rewards Std             0.4595
exploration/Rewards Max             2.62422
exploration/Rewards Min            -0.790263
exploration/Returns Mean           85.4909
exploration/Returns Std             4.71275
exploration/Returns Max            97.2173
exploration/Returns Min            77.0815
exploration/Actions Mean            0.56794
exploration/Actions Std             0.713219
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              19
exploration/Average Returns        85.4909
evaluation/num steps total      69791
evaluation/num paths total       4861
evaluation/path length Mean        49.97
evaluation/path length Std          1.2685
evaluation/path length Max         52
evaluation/path length Min         47
evaluation/Rewards Mean             1.71406
evaluation/Rewards Std              0.333575
evaluation/Rewards Max              2.69586
evaluation/Rewards Min              1.00573
evaluation/Returns Mean            85.6516
evaluation/Returns Std              2.35781
evaluation/Returns Max             89.2073
evaluation/Returns Min             79.9032
evaluation/Actions Mean             0.633387
evaluation/Actions Std              0.70302
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths              100
evaluation/Average Returns         85.6516
time/data storing (s)               0.00340357
time/evaluation sampling (s)        1.79955
time/exploration sampling (s)       0.381658
time/logging (s)                    0.0102864
time/saving (s)                     0.00474053
time/training (s)                   3.54128
time/epoch (s)                      5.74091
time/total (s)                     84.9844
Epoch                              13
-----------------------------  ----------------
2021-07-02 23:30:13.125795 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 14 finished
-----------------------------  ----------------
replay_buffer/size              16000
trainer/QF1 Loss               509827
trainer/QF2 Loss               269093
trainer/Policy Loss             -3521.82
trainer/Q1 Predictions Mean      2892.01
trainer/Q1 Predictions Std       5617.28
trainer/Q1 Predictions Max      22718.9
trainer/Q1 Predictions Min       -832.481
trainer/Q2 Predictions Mean      2855.18
trainer/Q2 Predictions Std       5559.69
trainer/Q2 Predictions Max      22770.6
trainer/Q2 Predictions Min       -166.432
trainer/Q Targets Mean           2812.22
trainer/Q Targets Std            5487.63
trainer/Q Targets Max           23056.9
trainer/Q Targets Min            -246.27
trainer/Bellman Errors 1 Mean  509827
trainer/Bellman Errors 1 Std        3.65526e+06
trainer/Bellman Errors 1 Max        3.88867e+07
trainer/Bellman Errors 1 Min        0.565525
trainer/Bellman Errors 2 Mean  269093
trainer/Bellman Errors 2 Std        1.86331e+06
trainer/Bellman Errors 2 Max        1.90812e+07
trainer/Bellman Errors 2 Min        0.212645
trainer/Policy Action Mean          0.783883
trainer/Policy Action Std           0.586424
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     16000
exploration/num paths total      1040
exploration/path length Mean       22.7273
exploration/path length Std         0.537825
exploration/path length Max        24
exploration/path length Min        21
exploration/Rewards Mean            1.75164
exploration/Rewards Std             0.456062
exploration/Rewards Max             2.43269
exploration/Rewards Min             1.00857
exploration/Returns Mean           39.8101
exploration/Returns Std             1.11006
exploration/Returns Max            42.515
exploration/Returns Min            36.2195
exploration/Actions Mean            0.732493
exploration/Actions Std             0.586839
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              44
exploration/Average Returns        39.8101
evaluation/num steps total      74781
evaluation/num paths total       5086
evaluation/path length Mean        22.1778
evaluation/path length Std          0.382326
evaluation/path length Max         23
evaluation/path length Min         22
evaluation/Rewards Mean             1.7476
evaluation/Rewards Std              0.457999
evaluation/Rewards Max              2.41602
evaluation/Rewards Min              1.00603
evaluation/Returns Mean            38.7579
evaluation/Returns Std              0.678102
evaluation/Returns Max             40.5908
evaluation/Returns Min             37.9325
evaluation/Actions Mean             0.774808
evaluation/Actions Std              0.599393
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths              225
evaluation/Average Returns         38.7579
time/data storing (s)               0.0035322
time/evaluation sampling (s)        1.82967
time/exploration sampling (s)       0.382406
time/logging (s)                    0.0112016
time/saving (s)                     0.00362473
time/training (s)                   3.57217
time/epoch (s)                      5.80261
time/total (s)                     90.79
Epoch                              14
-----------------------------  ----------------
2021-07-02 23:30:18.890607 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 15 finished
-----------------------------  ----------------
replay_buffer/size              17000
trainer/QF1 Loss               107435
trainer/QF2 Loss               124845
trainer/Policy Loss             -5945.91
trainer/Q1 Predictions Mean      4733.39
trainer/Q1 Predictions Std       6245.29
trainer/Q1 Predictions Max      21740.1
trainer/Q1 Predictions Min       -801.534
trainer/Q2 Predictions Mean      4776.17
trainer/Q2 Predictions Std       6238.92
trainer/Q2 Predictions Max      21791.6
trainer/Q2 Predictions Min       -102.54
trainer/Q Targets Mean           4676.17
trainer/Q Targets Std            6254.89
trainer/Q Targets Max           21684.8
trainer/Q Targets Min           -1131.29
trainer/Bellman Errors 1 Mean  107435
trainer/Bellman Errors 1 Std   241599
trainer/Bellman Errors 1 Max        2.27185e+06
trainer/Bellman Errors 1 Min        0.237793
trainer/Bellman Errors 2 Mean  124845
trainer/Bellman Errors 2 Std   321562
trainer/Bellman Errors 2 Max        3.80633e+06
trainer/Bellman Errors 2 Min        0.155342
trainer/Policy Action Mean          0.853263
trainer/Policy Action Std           0.467303
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     17000
exploration/num paths total      1060
exploration/path length Mean       50
exploration/path length Std        10.3344
exploration/path length Max        53
exploration/path length Min         5
exploration/Rewards Mean            1.37906
exploration/Rewards Std             0.722238
exploration/Rewards Max             2.41313
exploration/Rewards Min            -0.951869
exploration/Returns Mean           68.953
exploration/Returns Std            14.5836
exploration/Returns Max            73.3023
exploration/Returns Min             5.44591
exploration/Actions Mean            0.492628
exploration/Actions Std             0.751858
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              20
exploration/Average Returns        68.953
evaluation/num steps total      79776
evaluation/num paths total       5181
evaluation/path length Mean        52.5789
evaluation/path length Std          0.514607
evaluation/path length Max         54
evaluation/path length Min         52
evaluation/Rewards Mean             1.37379
evaluation/Rewards Std              0.756988
evaluation/Rewards Max              2.41433
evaluation/Rewards Min             -1.06785
evaluation/Returns Mean            72.2325
evaluation/Returns Std              0.507475
evaluation/Returns Max             73.537
evaluation/Returns Min             71.2434
evaluation/Actions Mean             0.506457
evaluation/Actions Std              0.773146
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               95
evaluation/Average Returns         72.2325
time/data storing (s)               0.00339545
time/evaluation sampling (s)        1.79124
time/exploration sampling (s)       0.368907
time/logging (s)                    0.0102511
time/saving (s)                     0.00356764
time/training (s)                   3.58355
time/epoch (s)                      5.7609
time/total (s)                     96.5535
Epoch                              15
-----------------------------  ----------------
2021-07-02 23:30:24.673032 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 16 finished
-----------------------------  ----------------
replay_buffer/size              18000
trainer/QF1 Loss               330387
trainer/QF2 Loss               290674
trainer/Policy Loss             -6367.57
trainer/Q1 Predictions Mean      5143.03
trainer/Q1 Predictions Std       6321.53
trainer/Q1 Predictions Max      21179.3
trainer/Q1 Predictions Min       -309.164
trainer/Q2 Predictions Mean      5112.57
trainer/Q2 Predictions Std       6326.67
trainer/Q2 Predictions Max      21158.8
trainer/Q2 Predictions Min        -79.2649
trainer/Q Targets Mean           5089.93
trainer/Q Targets Std            6313.93
trainer/Q Targets Max           21697.7
trainer/Q Targets Min            -199.831
trainer/Bellman Errors 1 Mean  330387
trainer/Bellman Errors 1 Std        2.57745e+06
trainer/Bellman Errors 1 Max        4.02206e+07
trainer/Bellman Errors 1 Min        0.24033
trainer/Bellman Errors 2 Mean  290674
trainer/Bellman Errors 2 Std        2.15709e+06
trainer/Bellman Errors 2 Max        3.32748e+07
trainer/Bellman Errors 2 Min        0.00878041
trainer/Policy Action Mean          0.555895
trainer/Policy Action Std           0.751895
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     18000
exploration/num paths total      1074
exploration/path length Mean       71.4286
exploration/path length Std         4.74664
exploration/path length Max        77
exploration/path length Min        60
exploration/Rewards Mean            1.73267
exploration/Rewards Std             0.518627
exploration/Rewards Max             3.09238
exploration/Rewards Min             0.556204
exploration/Returns Mean          123.762
exploration/Returns Std             9.39024
exploration/Returns Max           136.75
exploration/Returns Min           100.498
exploration/Actions Mean            0.545416
exploration/Actions Std             0.701404
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              14
exploration/Average Returns       123.762
evaluation/num steps total      84717
evaluation/num paths total       5253
evaluation/path length Mean        68.625
evaluation/path length Std          3.87455
evaluation/path length Max         78
evaluation/path length Min         64
evaluation/Rewards Mean             1.72523
evaluation/Rewards Std              0.509055
evaluation/Rewards Max              3.00917
evaluation/Rewards Min              0.578019
evaluation/Returns Mean           118.394
evaluation/Returns Std              6.86486
evaluation/Returns Max            134.947
evaluation/Returns Min            109.599
evaluation/Actions Mean             0.564256
evaluation/Actions Std              0.732674
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               72
evaluation/Average Returns        118.394
time/data storing (s)               0.00347665
time/evaluation sampling (s)        1.76866
time/exploration sampling (s)       0.37176
time/logging (s)                    0.0100853
time/saving (s)                     0.00357155
time/training (s)                   3.62179
time/epoch (s)                      5.77934
time/total (s)                    102.335
Epoch                              16
-----------------------------  ----------------
2021-07-02 23:30:30.433738 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 17 finished
-----------------------------  ----------------
replay_buffer/size              19000
trainer/QF1 Loss               717590
trainer/QF2 Loss               980317
trainer/Policy Loss             -7180.16
trainer/Q1 Predictions Mean      5861.54
trainer/Q1 Predictions Std       6556.86
trainer/Q1 Predictions Max      20372.6
trainer/Q1 Predictions Min       -126.382
trainer/Q2 Predictions Mean      5919.59
trainer/Q2 Predictions Std       6521.56
trainer/Q2 Predictions Max      20395.9
trainer/Q2 Predictions Min        -92.8359
trainer/Q Targets Mean           5763.83
trainer/Q Targets Std            6560.1
trainer/Q Targets Max           20258.1
trainer/Q Targets Min            -217.839
trainer/Bellman Errors 1 Mean  717590
trainer/Bellman Errors 1 Std        7.71321e+06
trainer/Bellman Errors 1 Max        1.19745e+08
trainer/Bellman Errors 1 Min        0.798249
trainer/Bellman Errors 2 Mean  980317
trainer/Bellman Errors 2 Std        8.06369e+06
trainer/Bellman Errors 2 Max        1.19533e+08
trainer/Bellman Errors 2 Min        0.0120462
trainer/Policy Action Mean          0.547537
trainer/Policy Action Std           0.764355
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     19000
exploration/num paths total      1095
exploration/path length Mean       47.619
exploration/path length Std         3.61842
exploration/path length Max        51
exploration/path length Min        33
exploration/Rewards Mean            1.43246
exploration/Rewards Std             0.557408
exploration/Rewards Max             2.33153
exploration/Rewards Min            -0.0883684
exploration/Returns Mean           68.2125
exploration/Returns Std             3.99464
exploration/Returns Max            73.1723
exploration/Returns Min            53.6971
exploration/Actions Mean            0.349321
exploration/Actions Std             0.796769
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              21
exploration/Average Returns        68.2125
evaluation/num steps total      89699
evaluation/num paths total       5355
evaluation/path length Mean        48.8431
evaluation/path length Std          1.41937
evaluation/path length Max         52
evaluation/path length Min         43
evaluation/Rewards Mean             1.42774
evaluation/Rewards Std              0.585145
evaluation/Rewards Max              2.35037
evaluation/Rewards Min             -0.128239
evaluation/Returns Mean            69.7353
evaluation/Returns Std              2.17623
evaluation/Returns Max             73.7584
evaluation/Returns Min             60.5431
evaluation/Actions Mean             0.362205
evaluation/Actions Std              0.816257
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths              102
evaluation/Average Returns         69.7353
time/data storing (s)               0.00342046
time/evaluation sampling (s)        1.75622
time/exploration sampling (s)       0.365278
time/logging (s)                    0.0103
time/saving (s)                     0.00355864
time/training (s)                   3.61928
time/epoch (s)                      5.75805
time/total (s)                    108.096
Epoch                              17
-----------------------------  ----------------
2021-07-02 23:30:36.210732 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 18 finished
-----------------------------  ----------------
replay_buffer/size              20000
trainer/QF1 Loss               860201
trainer/QF2 Loss               826755
trainer/Policy Loss             -7196.24
trainer/Q1 Predictions Mean      6061.18
trainer/Q1 Predictions Std       7189.68
trainer/Q1 Predictions Max      20098.5
trainer/Q1 Predictions Min       -145.307
trainer/Q2 Predictions Mean      6056.03
trainer/Q2 Predictions Std       7184.12
trainer/Q2 Predictions Max      20009.2
trainer/Q2 Predictions Min       -116.039
trainer/Q Targets Mean           5966.7
trainer/Q Targets Std            7136.97
trainer/Q Targets Max           20815.9
trainer/Q Targets Min            -162.811
trainer/Bellman Errors 1 Mean  860201
trainer/Bellman Errors 1 Std        1.14875e+07
trainer/Bellman Errors 1 Max        1.84176e+08
trainer/Bellman Errors 1 Min        0.0362736
trainer/Bellman Errors 2 Mean  826755
trainer/Bellman Errors 2 Std        1.11955e+07
trainer/Bellman Errors 2 Max        1.79513e+08
trainer/Bellman Errors 2 Min        0.0708843
trainer/Policy Action Mean          0.513134
trainer/Policy Action Std           0.800752
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     20000
exploration/num paths total      1117
exploration/path length Mean       45.4545
exploration/path length Std         3.73834
exploration/path length Max        48
exploration/path length Min        34
exploration/Rewards Mean            1.43558
exploration/Rewards Std             0.554756
exploration/Rewards Max             2.33119
exploration/Rewards Min            -0.178086
exploration/Returns Mean           65.2539
exploration/Returns Std             2.54965
exploration/Returns Max            67.3658
exploration/Returns Min            57.6103
exploration/Actions Mean            0.389891
exploration/Actions Std             0.768387
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              22
exploration/Average Returns        65.2539
evaluation/num steps total      94682
evaluation/num paths total       5482
evaluation/path length Mean        39.2362
evaluation/path length Std          6.53333
evaluation/path length Max         47
evaluation/path length Min         33
evaluation/Rewards Mean             1.54457
evaluation/Rewards Std              0.509563
evaluation/Rewards Max              2.34821
evaluation/Rewards Min             -0.231202
evaluation/Returns Mean            60.6029
evaluation/Returns Std              4.3996
evaluation/Returns Max             66.551
evaluation/Returns Min             55.244
evaluation/Actions Mean             0.418037
evaluation/Actions Std              0.787115
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths              127
evaluation/Average Returns         60.6029
time/data storing (s)               0.00341617
time/evaluation sampling (s)        1.77371
time/exploration sampling (s)       0.372299
time/logging (s)                    0.0105648
time/saving (s)                     0.00355668
time/training (s)                   3.61086
time/epoch (s)                      5.7744
time/total (s)                    113.873
Epoch                              18
-----------------------------  ----------------
2021-07-02 23:30:42.079658 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 19 finished
-----------------------------  ----------------
replay_buffer/size              21000
trainer/QF1 Loss               590679
trainer/QF2 Loss               583905
trainer/Policy Loss             -6922.27
trainer/Q1 Predictions Mean      6019.79
trainer/Q1 Predictions Std       7276.43
trainer/Q1 Predictions Max      21843.8
trainer/Q1 Predictions Min       -283.629
trainer/Q2 Predictions Mean      6008.95
trainer/Q2 Predictions Std       7244.95
trainer/Q2 Predictions Max      21796
trainer/Q2 Predictions Min       -118.832
trainer/Q Targets Mean           5994.56
trainer/Q Targets Std            7300.1
trainer/Q Targets Max           21524.4
trainer/Q Targets Min            -337.515
trainer/Bellman Errors 1 Mean  590679
trainer/Bellman Errors 1 Std        6.24041e+06
trainer/Bellman Errors 1 Max        9.96638e+07
trainer/Bellman Errors 1 Min        0.548128
trainer/Bellman Errors 2 Mean  583905
trainer/Bellman Errors 2 Std        6.15002e+06
trainer/Bellman Errors 2 Max        9.78355e+07
trainer/Bellman Errors 2 Min        0.497964
trainer/Policy Action Mean          0.379532
trainer/Policy Action Std           0.859147
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     21000
exploration/num paths total      1166
exploration/path length Mean       20.4082
exploration/path length Std        11.8561
exploration/path length Max        54
exploration/path length Min        13
exploration/Rewards Mean            1.11248
exploration/Rewards Std             0.38492
exploration/Rewards Max             2.16574
exploration/Rewards Min             0.430907
exploration/Returns Mean           22.7037
exploration/Returns Std            21.0335
exploration/Returns Max            85.9277
exploration/Returns Min            10.1779
exploration/Actions Mean            0.237325
exploration/Actions Std             0.785
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              49
exploration/Average Returns        22.7037
evaluation/num steps total      99669
evaluation/num paths total       5805
evaluation/path length Mean        15.4396
evaluation/path length Std          5.99628
evaluation/path length Max         57
evaluation/path length Min         13
evaluation/Rewards Mean             0.90983
evaluation/Rewards Std              0.288171
evaluation/Rewards Max              2.2235
evaluation/Rewards Min              0.422756
evaluation/Returns Mean            14.0474
evaluation/Returns Std             10.4581
evaluation/Returns Max             91.4464
evaluation/Returns Min             10.0871
evaluation/Actions Mean             0.31263
evaluation/Actions Std              0.805558
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths              323
evaluation/Average Returns         14.0474
time/data storing (s)               0.00348901
time/evaluation sampling (s)        1.85854
time/exploration sampling (s)       0.385303
time/logging (s)                    0.0124401
time/saving (s)                     0.00356647
time/training (s)                   3.60462
time/epoch (s)                      5.86796
time/total (s)                    119.743
Epoch                              19
-----------------------------  ----------------
2021-07-02 23:30:47.869760 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 20 finished
-----------------------------  ----------------
replay_buffer/size              22000
trainer/QF1 Loss               107320
trainer/QF2 Loss               136680
trainer/Policy Loss             -6572.19
trainer/Q1 Predictions Mean      5690.41
trainer/Q1 Predictions Std       6818.35
trainer/Q1 Predictions Max      21936
trainer/Q1 Predictions Min       -382.698
trainer/Q2 Predictions Mean      5703.95
trainer/Q2 Predictions Std       6812.65
trainer/Q2 Predictions Max      21878
trainer/Q2 Predictions Min        -77.8283
trainer/Q Targets Mean           5644.8
trainer/Q Targets Std            6810.76
trainer/Q Targets Max           21661.2
trainer/Q Targets Min            -457.979
trainer/Bellman Errors 1 Mean  107320
trainer/Bellman Errors 1 Std   624024
trainer/Bellman Errors 1 Max        9.45451e+06
trainer/Bellman Errors 1 Min        0.246715
trainer/Bellman Errors 2 Mean  136680
trainer/Bellman Errors 2 Std   918436
trainer/Bellman Errors 2 Max        1.41946e+07
trainer/Bellman Errors 2 Min        0.993666
trainer/Policy Action Mean          0.286011
trainer/Policy Action Std           0.87966
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     22000
exploration/num paths total      1171
exploration/path length Mean      200
exploration/path length Std        77.2192
exploration/path length Max       258
exploration/path length Min        47
exploration/Rewards Mean            1.53396
exploration/Rewards Std             0.289575
exploration/Rewards Max             2.26925
exploration/Rewards Min             0.784321
exploration/Returns Mean          306.792
exploration/Returns Std           118.85
exploration/Returns Max           386.125
exploration/Returns Min            70.1015
exploration/Actions Mean            0.0893936
exploration/Actions Std             0.786236
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               5
exploration/Average Returns       306.792
evaluation/num steps total     104465
evaluation/num paths total       5825
evaluation/path length Mean       239.8
evaluation/path length Std         38.1243
evaluation/path length Max        315
evaluation/path length Min        138
evaluation/Rewards Mean             1.50374
evaluation/Rewards Std              0.300242
evaluation/Rewards Max              2.30484
evaluation/Rewards Min              0.719354
evaluation/Returns Mean           360.597
evaluation/Returns Std             59.4066
evaluation/Returns Max            447.761
evaluation/Returns Min            191.806
evaluation/Actions Mean             0.0881877
evaluation/Actions Std              0.793972
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               20
evaluation/Average Returns        360.597
time/data storing (s)               0.00338696
time/evaluation sampling (s)        1.79261
time/exploration sampling (s)       0.378652
time/logging (s)                    0.00946972
time/saving (s)                     0.00354956
time/training (s)                   3.59595
time/epoch (s)                      5.78362
time/total (s)                    125.53
Epoch                              20
-----------------------------  ----------------
2021-07-02 23:30:53.691617 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 21 finished
-----------------------------  ----------------
replay_buffer/size              23000
trainer/QF1 Loss               127179
trainer/QF2 Loss               129996
trainer/Policy Loss             -5922.34
trainer/Q1 Predictions Mean      4690.39
trainer/Q1 Predictions Std       5911.41
trainer/Q1 Predictions Max      19812.5
trainer/Q1 Predictions Min       -207.884
trainer/Q2 Predictions Mean      4677.36
trainer/Q2 Predictions Std       5905.98
trainer/Q2 Predictions Max      19730.3
trainer/Q2 Predictions Min        -70.5983
trainer/Q Targets Mean           4684.71
trainer/Q Targets Std            5949.03
trainer/Q Targets Max           19857.1
trainer/Q Targets Min            -209.637
trainer/Bellman Errors 1 Mean  127179
trainer/Bellman Errors 1 Std   426872
trainer/Bellman Errors 1 Max        4.02281e+06
trainer/Bellman Errors 1 Min        0.000499025
trainer/Bellman Errors 2 Mean  129996
trainer/Bellman Errors 2 Std   420711
trainer/Bellman Errors 2 Max        3.936e+06
trainer/Bellman Errors 2 Min        0.0165422
trainer/Policy Action Mean          0.0438967
trainer/Policy Action Std           0.837974
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     23000
exploration/num paths total      1173
exploration/path length Mean      500
exploration/path length Std       151
exploration/path length Max       651
exploration/path length Min       349
exploration/Rewards Mean            1.14429
exploration/Rewards Std             0.204881
exploration/Rewards Max             2.1613
exploration/Rewards Min             0.503042
exploration/Returns Mean          572.145
exploration/Returns Std           192.432
exploration/Returns Max           764.577
exploration/Returns Min           379.714
exploration/Actions Mean            0.12778
exploration/Actions Std             0.474078
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       572.145
evaluation/num steps total     109040
evaluation/num paths total       5832
evaluation/path length Mean       653.571
evaluation/path length Std         23.7478
evaluation/path length Max        687
evaluation/path length Min        620
evaluation/Rewards Mean             1.17396
evaluation/Rewards Std              0.217416
evaluation/Rewards Max              2.18978
evaluation/Rewards Min              0.435003
evaluation/Returns Mean           767.264
evaluation/Returns Std             23.8774
evaluation/Returns Max            800.745
evaluation/Returns Min            733.726
evaluation/Actions Mean             0.126025
evaluation/Actions Std              0.42588
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths                7
evaluation/Average Returns        767.264
time/data storing (s)               0.00340524
time/evaluation sampling (s)        1.81567
time/exploration sampling (s)       0.381302
time/logging (s)                    0.00902306
time/saving (s)                     0.00349557
time/training (s)                   3.60564
time/epoch (s)                      5.81853
time/total (s)                    131.351
Epoch                              21
-----------------------------  ----------------
2021-07-02 23:30:59.555408 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 22 finished
-----------------------------  ----------------
replay_buffer/size              24000
trainer/QF1 Loss               146657
trainer/QF2 Loss               129901
trainer/Policy Loss             -7724.06
trainer/Q1 Predictions Mean      6331.62
trainer/Q1 Predictions Std       6623.82
trainer/Q1 Predictions Max      20508.7
trainer/Q1 Predictions Min       -210.667
trainer/Q2 Predictions Mean      6301.92
trainer/Q2 Predictions Std       6633.42
trainer/Q2 Predictions Max      20265.3
trainer/Q2 Predictions Min       -145.045
trainer/Q Targets Mean           6267.72
trainer/Q Targets Std            6587.39
trainer/Q Targets Max           20171.8
trainer/Q Targets Min            -191.205
trainer/Bellman Errors 1 Mean  146657
trainer/Bellman Errors 1 Std   491186
trainer/Bellman Errors 1 Max        5.49379e+06
trainer/Bellman Errors 1 Min        0.170788
trainer/Bellman Errors 2 Mean  129901
trainer/Bellman Errors 2 Std   513401
trainer/Bellman Errors 2 Max        6.42551e+06
trainer/Bellman Errors 2 Min        0.419255
trainer/Policy Action Mean          0.0812738
trainer/Policy Action Std           0.791976
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     24000
exploration/num paths total      1180
exploration/path length Mean      142.857
exploration/path length Std        31.4299
exploration/path length Max       163
exploration/path length Min        67
exploration/Rewards Mean            0.807171
exploration/Rewards Std             0.110174
exploration/Rewards Max             0.966965
exploration/Rewards Min             0.338188
exploration/Returns Mean          115.31
exploration/Returns Std            27.0403
exploration/Returns Max           133.421
exploration/Returns Min            50.1
exploration/Actions Mean            0.065452
exploration/Actions Std             0.193281
exploration/Actions Max             1
exploration/Actions Min            -0.980334
exploration/Num Paths               7
exploration/Average Returns       115.31
evaluation/num steps total     114035
evaluation/num paths total       5863
evaluation/path length Mean       161.129
evaluation/path length Std          2.09056
evaluation/path length Max        165
evaluation/path length Min        156
evaluation/Rewards Mean             0.815253
evaluation/Rewards Std              0.104322
evaluation/Rewards Max              0.962709
evaluation/Rewards Min              0.416251
evaluation/Returns Mean           131.361
evaluation/Returns Std              1.60188
evaluation/Returns Max            134.377
evaluation/Returns Min            127.388
evaluation/Actions Mean             0.0681975
evaluation/Actions Std              0.127565
evaluation/Actions Max              0.928741
evaluation/Actions Min             -0.832646
evaluation/Num Paths               31
evaluation/Average Returns        131.361
time/data storing (s)               0.00333454
time/evaluation sampling (s)        1.836
time/exploration sampling (s)       0.384517
time/logging (s)                    0.00980563
time/saving (s)                     0.00352568
time/training (s)                   3.6245
time/epoch (s)                      5.86169
time/total (s)                    137.215
Epoch                              22
-----------------------------  ----------------
2021-07-02 23:31:05.383420 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 23 finished
-----------------------------  ----------------
replay_buffer/size              25000
trainer/QF1 Loss                82938
trainer/QF2 Loss                82214.5
trainer/Policy Loss             -8851.66
trainer/Q1 Predictions Mean      7518.01
trainer/Q1 Predictions Std       7033.24
trainer/Q1 Predictions Max      20003.1
trainer/Q1 Predictions Min       -210.063
trainer/Q2 Predictions Mean      7533.5
trainer/Q2 Predictions Std       7045.75
trainer/Q2 Predictions Max      19736.2
trainer/Q2 Predictions Min       -262.79
trainer/Q Targets Mean           7480.29
trainer/Q Targets Std            7042.38
trainer/Q Targets Max           20103
trainer/Q Targets Min            -199.648
trainer/Bellman Errors 1 Mean   82938
trainer/Bellman Errors 1 Std   175365
trainer/Bellman Errors 1 Max        1.28299e+06
trainer/Bellman Errors 1 Min        0.273093
trainer/Bellman Errors 2 Mean   82214.5
trainer/Bellman Errors 2 Std   171636
trainer/Bellman Errors 2 Max        1.19205e+06
trainer/Bellman Errors 2 Min        0.172726
trainer/Policy Action Mean          0.275373
trainer/Policy Action Std           0.756682
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     25000
exploration/num paths total      1188
exploration/path length Mean      125
exploration/path length Std        35.7316
exploration/path length Max       142
exploration/path length Min        31
exploration/Rewards Mean            0.78104
exploration/Rewards Std             0.163614
exploration/Rewards Max             1.02492
exploration/Rewards Min             0.347941
exploration/Returns Mean           97.6301
exploration/Returns Std            30.1636
exploration/Returns Max           113.015
exploration/Returns Min            18.3966
exploration/Actions Mean            0.139467
exploration/Actions Std             0.275228
exploration/Actions Max             1
exploration/Actions Min            -0.943444
exploration/Num Paths               8
exploration/Average Returns        97.6301
evaluation/num steps total     119008
evaluation/num paths total       5903
evaluation/path length Mean       124.325
evaluation/path length Std          1.47288
evaluation/path length Max        127
evaluation/path length Min        122
evaluation/Rewards Mean             0.773242
evaluation/Rewards Std              0.159719
evaluation/Rewards Max              0.971856
evaluation/Rewards Min              0.349853
evaluation/Returns Mean            96.1334
evaluation/Returns Std              0.894527
evaluation/Returns Max             97.9646
evaluation/Returns Min             94.6176
evaluation/Actions Mean             0.128524
evaluation/Actions Std              0.209243
evaluation/Actions Max              0.841803
evaluation/Actions Min             -0.932809
evaluation/Num Paths               40
evaluation/Average Returns         96.1334
time/data storing (s)               0.00341707
time/evaluation sampling (s)        1.82598
time/exploration sampling (s)       0.384107
time/logging (s)                    0.00972264
time/saving (s)                     0.00358446
time/training (s)                   3.59803
time/epoch (s)                      5.82484
time/total (s)                    143.043
Epoch                              23
-----------------------------  ----------------
2021-07-02 23:31:11.263524 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 24 finished
-----------------------------  ----------------
replay_buffer/size              26000
trainer/QF1 Loss               102986
trainer/QF2 Loss               108362
trainer/Policy Loss             -9138.9
trainer/Q1 Predictions Mean      8112.2
trainer/Q1 Predictions Std       6951.78
trainer/Q1 Predictions Max      19670.3
trainer/Q1 Predictions Min       -320.845
trainer/Q2 Predictions Mean      8114.35
trainer/Q2 Predictions Std       6948.99
trainer/Q2 Predictions Max      19813.6
trainer/Q2 Predictions Min       -280.323
trainer/Q Targets Mean           8153.71
trainer/Q Targets Std            6974.38
trainer/Q Targets Max           19216.1
trainer/Q Targets Min            -318.036
trainer/Bellman Errors 1 Mean  102986
trainer/Bellman Errors 1 Std   352910
trainer/Bellman Errors 1 Max        4.39173e+06
trainer/Bellman Errors 1 Min        0.200047
trainer/Bellman Errors 2 Mean  108362
trainer/Bellman Errors 2 Std   360140
trainer/Bellman Errors 2 Max        3.95544e+06
trainer/Bellman Errors 2 Min        0.394142
trainer/Policy Action Mean          0.276744
trainer/Policy Action Std           0.788003
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     26000
exploration/num paths total      1189
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.984257
exploration/Rewards Std             0.0560551
exploration/Rewards Max             1.05945
exploration/Rewards Min             0.444124
exploration/Returns Mean          984.257
exploration/Returns Std             0
exploration/Returns Max           984.257
exploration/Returns Min           984.257
exploration/Actions Mean            0.352884
exploration/Actions Std             0.307405
exploration/Actions Max             1
exploration/Actions Min            -0.902921
exploration/Num Paths               1
exploration/Average Returns       984.257
evaluation/num steps total     124008
evaluation/num paths total       5908
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.984003
evaluation/Rewards Std              0.0595141
evaluation/Rewards Max              1.02632
evaluation/Rewards Min              0.396338
evaluation/Returns Mean           984.003
evaluation/Returns Std              0.219412
evaluation/Returns Max            984.256
evaluation/Returns Min            983.671
evaluation/Actions Mean             0.34601
evaluation/Actions Std              0.270411
evaluation/Actions Max              0.999274
evaluation/Actions Min             -0.94072
evaluation/Num Paths                5
evaluation/Average Returns        984.003
time/data storing (s)               0.00342062
time/evaluation sampling (s)        1.83271
time/exploration sampling (s)       0.385661
time/logging (s)                    0.00963312
time/saving (s)                     0.00356115
time/training (s)                   3.64214
time/epoch (s)                      5.87713
time/total (s)                    148.922
Epoch                              24
-----------------------------  ----------------
2021-07-02 23:31:17.116553 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 25 finished
-----------------------------  ----------------
replay_buffer/size              27000
trainer/QF1 Loss                57828.7
trainer/QF2 Loss                59252.6
trainer/Policy Loss             -9124.83
trainer/Q1 Predictions Mean      7941.16
trainer/Q1 Predictions Std       7047.99
trainer/Q1 Predictions Max      19161.6
trainer/Q1 Predictions Min       -364.133
trainer/Q2 Predictions Mean      7921.86
trainer/Q2 Predictions Std       7041.89
trainer/Q2 Predictions Max      19367.5
trainer/Q2 Predictions Min       -235.719
trainer/Q Targets Mean           7933.96
trainer/Q Targets Std            7059.07
trainer/Q Targets Max           18937.5
trainer/Q Targets Min            -314.659
trainer/Bellman Errors 1 Mean   57828.7
trainer/Bellman Errors 1 Std   143781
trainer/Bellman Errors 1 Max        1.69011e+06
trainer/Bellman Errors 1 Min        0.970437
trainer/Bellman Errors 2 Mean   59252.6
trainer/Bellman Errors 2 Std   143780
trainer/Bellman Errors 2 Max        1.68707e+06
trainer/Bellman Errors 2 Min        0.000110209
trainer/Policy Action Mean          0.370345
trainer/Policy Action Std           0.763957
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     27000
exploration/num paths total      1190
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.988745
exploration/Rewards Std             0.0677282
exploration/Rewards Max             1.20847
exploration/Rewards Min             0.430063
exploration/Returns Mean          988.745
exploration/Returns Std             0
exploration/Returns Max           988.745
exploration/Returns Min           988.745
exploration/Actions Mean            0.208904
exploration/Actions Std             0.463874
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       988.745
evaluation/num steps total     129008
evaluation/num paths total       5913
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.989084
evaluation/Rewards Std              0.0715598
evaluation/Rewards Max              1.33786
evaluation/Rewards Min              0.366894
evaluation/Returns Mean           989.084
evaluation/Returns Std              0.424683
evaluation/Returns Max            989.516
evaluation/Returns Min            988.301
evaluation/Actions Mean             0.195468
evaluation/Actions Std              0.440135
evaluation/Actions Max              0.999971
evaluation/Actions Min             -0.996209
evaluation/Num Paths                5
evaluation/Average Returns        989.084
time/data storing (s)               0.00337266
time/evaluation sampling (s)        1.82921
time/exploration sampling (s)       0.384646
time/logging (s)                    0.00975908
time/saving (s)                     0.00355324
time/training (s)                   3.61959
time/epoch (s)                      5.85013
time/total (s)                    154.775
Epoch                              25
-----------------------------  ----------------
2021-07-02 23:31:23.047645 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 26 finished
-----------------------------  ----------------
replay_buffer/size              28000
trainer/QF1 Loss               271454
trainer/QF2 Loss               262103
trainer/Policy Loss             -9827.24
trainer/Q1 Predictions Mean      8866.41
trainer/Q1 Predictions Std       7185.78
trainer/Q1 Predictions Max      19814.5
trainer/Q1 Predictions Min       -341.276
trainer/Q2 Predictions Mean      8853.88
trainer/Q2 Predictions Std       7178.31
trainer/Q2 Predictions Max      19366.1
trainer/Q2 Predictions Min       -268.467
trainer/Q Targets Mean           8770.33
trainer/Q Targets Std            7190.59
trainer/Q Targets Max           19593.6
trainer/Q Targets Min            -358.837
trainer/Bellman Errors 1 Mean  271454
trainer/Bellman Errors 1 Std        3.34333e+06
trainer/Bellman Errors 1 Max        5.36178e+07
trainer/Bellman Errors 1 Min        2.26467
trainer/Bellman Errors 2 Mean  262103
trainer/Bellman Errors 2 Std        3.30478e+06
trainer/Bellman Errors 2 Max        5.30046e+07
trainer/Bellman Errors 2 Min        0.283265
trainer/Policy Action Mean          0.453839
trainer/Policy Action Std           0.723151
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     28000
exploration/num paths total      1191
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.99384
exploration/Rewards Std             0.0683794
exploration/Rewards Max             1.22038
exploration/Rewards Min             0.540611
exploration/Returns Mean          993.84
exploration/Returns Std             0
exploration/Returns Max           993.84
exploration/Returns Min           993.84
exploration/Actions Mean            0.209504
exploration/Actions Std             0.497637
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       993.84
evaluation/num steps total     134008
evaluation/num paths total       5918
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.992674
evaluation/Rewards Std              0.0739086
evaluation/Rewards Max              1.31472
evaluation/Rewards Min              0.396386
evaluation/Returns Mean           992.674
evaluation/Returns Std              0.590539
evaluation/Returns Max            993.333
evaluation/Returns Min            991.838
evaluation/Actions Mean             0.20401
evaluation/Actions Std              0.477711
evaluation/Actions Max              1
evaluation/Actions Min             -0.997444
evaluation/Num Paths                5
evaluation/Average Returns        992.674
time/data storing (s)               0.00342467
time/evaluation sampling (s)        1.82339
time/exploration sampling (s)       0.382785
time/logging (s)                    0.010211
time/saving (s)                     0.00370271
time/training (s)                   3.70481
time/epoch (s)                      5.92832
time/total (s)                    160.706
Epoch                              26
-----------------------------  ----------------
2021-07-02 23:31:28.930400 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 27 finished
-----------------------------  ----------------
replay_buffer/size              29000
trainer/QF1 Loss                    1.05114e+06
trainer/QF2 Loss                    1.02775e+06
trainer/Policy Loss             -9452.89
trainer/Q1 Predictions Mean      8387.47
trainer/Q1 Predictions Std       6982.6
trainer/Q1 Predictions Max      18913.3
trainer/Q1 Predictions Min       -158.088
trainer/Q2 Predictions Mean      8401.6
trainer/Q2 Predictions Std       6976.95
trainer/Q2 Predictions Max      18750.2
trainer/Q2 Predictions Min       -149.199
trainer/Q Targets Mean           8375.07
trainer/Q Targets Std            6990.26
trainer/Q Targets Max           18855.6
trainer/Q Targets Min            -197.982
trainer/Bellman Errors 1 Mean       1.05114e+06
trainer/Bellman Errors 1 Std        1.57006e+07
trainer/Bellman Errors 1 Max        2.51757e+08
trainer/Bellman Errors 1 Min        0.586182
trainer/Bellman Errors 2 Mean       1.02775e+06
trainer/Bellman Errors 2 Std        1.5372e+07
trainer/Bellman Errors 2 Max        2.46489e+08
trainer/Bellman Errors 2 Min        0.169834
trainer/Policy Action Mean          0.322054
trainer/Policy Action Std           0.754097
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     29000
exploration/num paths total      1192
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.98022
exploration/Rewards Std             0.121309
exploration/Rewards Max             1.34265
exploration/Rewards Min             0.389279
exploration/Returns Mean          980.22
exploration/Returns Std             0
exploration/Returns Max           980.22
exploration/Returns Min           980.22
exploration/Actions Mean            0.231281
exploration/Actions Std             0.494889
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       980.22
evaluation/num steps total     139008
evaluation/num paths total       5923
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.97998
evaluation/Rewards Std              0.10825
evaluation/Rewards Max              1.32427
evaluation/Rewards Min              0.501696
evaluation/Returns Mean           979.98
evaluation/Returns Std              0.630084
evaluation/Returns Max            980.894
evaluation/Returns Min            978.983
evaluation/Actions Mean             0.215465
evaluation/Actions Std              0.482705
evaluation/Actions Max              0.999973
evaluation/Actions Min             -0.994974
evaluation/Num Paths                5
evaluation/Average Returns        979.98
time/data storing (s)               0.00341286
time/evaluation sampling (s)        1.8491
time/exploration sampling (s)       0.381491
time/logging (s)                    0.0101207
time/saving (s)                     0.00352576
time/training (s)                   3.63178
time/epoch (s)                      5.87943
time/total (s)                    166.589
Epoch                              27
-----------------------------  ----------------
2021-07-02 23:31:34.902240 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 28 finished
-----------------------------  ----------------
replay_buffer/size              30000
trainer/QF1 Loss                83023.2
trainer/QF2 Loss                82958.5
trainer/Policy Loss             -9701.39
trainer/Q1 Predictions Mean      8793.16
trainer/Q1 Predictions Std       6877.48
trainer/Q1 Predictions Max      19458.7
trainer/Q1 Predictions Min       -253.401
trainer/Q2 Predictions Mean      8777.07
trainer/Q2 Predictions Std       6878.26
trainer/Q2 Predictions Max      19122.8
trainer/Q2 Predictions Min       -259.028
trainer/Q Targets Mean           8713.95
trainer/Q Targets Std            6865.03
trainer/Q Targets Max           19138
trainer/Q Targets Min            -210.029
trainer/Bellman Errors 1 Mean   83023.1
trainer/Bellman Errors 1 Std   290131
trainer/Bellman Errors 1 Max        4.18026e+06
trainer/Bellman Errors 1 Min        0.317506
trainer/Bellman Errors 2 Mean   82958.5
trainer/Bellman Errors 2 Std   317000
trainer/Bellman Errors 2 Max        4.74484e+06
trainer/Bellman Errors 2 Min        0.492536
trainer/Policy Action Mean          0.319859
trainer/Policy Action Std           0.743006
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     30000
exploration/num paths total      1193
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.981457
exploration/Rewards Std             0.0927559
exploration/Rewards Max             1.18517
exploration/Rewards Min             0.498442
exploration/Returns Mean          981.457
exploration/Returns Std             0
exploration/Returns Max           981.457
exploration/Returns Min           981.457
exploration/Actions Mean            0.249949
exploration/Actions Std             0.487878
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       981.457
evaluation/num steps total     144008
evaluation/num paths total       5928
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.982661
evaluation/Rewards Std              0.084586
evaluation/Rewards Max              1.20524
evaluation/Rewards Min              0.515773
evaluation/Returns Mean           982.661
evaluation/Returns Std              0.991779
evaluation/Returns Max            983.9
evaluation/Returns Min            981.367
evaluation/Actions Mean             0.253435
evaluation/Actions Std              0.474865
evaluation/Actions Max              0.999425
evaluation/Actions Min             -0.994812
evaluation/Num Paths                5
evaluation/Average Returns        982.661
time/data storing (s)               0.00342674
time/evaluation sampling (s)        1.83491
time/exploration sampling (s)       0.3823
time/logging (s)                    0.00995979
time/saving (s)                     0.00354304
time/training (s)                   3.73433
time/epoch (s)                      5.96847
time/total (s)                    172.56
Epoch                              28
-----------------------------  ----------------
2021-07-02 23:31:40.739726 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 29 finished
-----------------------------  ----------------
replay_buffer/size              31000
trainer/QF1 Loss               137278
trainer/QF2 Loss               129644
trainer/Policy Loss            -10687.4
trainer/Q1 Predictions Mean      9743.97
trainer/Q1 Predictions Std       6777.57
trainer/Q1 Predictions Max      18814.7
trainer/Q1 Predictions Min       -141.76
trainer/Q2 Predictions Mean      9726.4
trainer/Q2 Predictions Std       6779.01
trainer/Q2 Predictions Max      18810.2
trainer/Q2 Predictions Min       -110.727
trainer/Q Targets Mean           9726
trainer/Q Targets Std            6813.71
trainer/Q Targets Max           18632.5
trainer/Q Targets Min            -155.997
trainer/Bellman Errors 1 Mean  137278
trainer/Bellman Errors 1 Std   985642
trainer/Bellman Errors 1 Max        1.53413e+07
trainer/Bellman Errors 1 Min        0.0485416
trainer/Bellman Errors 2 Mean  129644
trainer/Bellman Errors 2 Std   881709
trainer/Bellman Errors 2 Max        1.36365e+07
trainer/Bellman Errors 2 Min        0.000186712
trainer/Policy Action Mean          0.334809
trainer/Policy Action Std           0.74642
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     31000
exploration/num paths total      1194
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.977158
exploration/Rewards Std             0.0923736
exploration/Rewards Max             1.22167
exploration/Rewards Min             0.445992
exploration/Returns Mean          977.158
exploration/Returns Std             0
exploration/Returns Max           977.158
exploration/Returns Min           977.158
exploration/Actions Mean            0.288395
exploration/Actions Std             0.589853
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       977.158
evaluation/num steps total     149008
evaluation/num paths total       5933
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.977353
evaluation/Rewards Std              0.0915399
evaluation/Rewards Max              1.22052
evaluation/Rewards Min              0.400172
evaluation/Returns Mean           977.353
evaluation/Returns Std              0.582794
evaluation/Returns Max            978.066
evaluation/Returns Min            976.578
evaluation/Actions Mean             0.287719
evaluation/Actions Std              0.592668
evaluation/Actions Max              1
evaluation/Actions Min             -0.995978
evaluation/Num Paths                5
evaluation/Average Returns        977.353
time/data storing (s)               0.00338808
time/evaluation sampling (s)        1.81517
time/exploration sampling (s)       0.382398
time/logging (s)                    0.0102088
time/saving (s)                     0.00352497
time/training (s)                   3.61977
time/epoch (s)                      5.83446
time/total (s)                    178.397
Epoch                              29
-----------------------------  ----------------
2021-07-02 23:31:46.579266 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 30 finished
-----------------------------  ----------------
replay_buffer/size              32000
trainer/QF1 Loss                89293.8
trainer/QF2 Loss                78901.5
trainer/Policy Loss            -10250.7
trainer/Q1 Predictions Mean      9288.67
trainer/Q1 Predictions Std       6270.25
trainer/Q1 Predictions Max      18190.6
trainer/Q1 Predictions Min       -231.504
trainer/Q2 Predictions Mean      9295.56
trainer/Q2 Predictions Std       6257.46
trainer/Q2 Predictions Max      17839.7
trainer/Q2 Predictions Min       -241.421
trainer/Q Targets Mean           9301.2
trainer/Q Targets Std            6286.17
trainer/Q Targets Max           17684.5
trainer/Q Targets Min            -182.779
trainer/Bellman Errors 1 Mean   89293.8
trainer/Bellman Errors 1 Std   574929
trainer/Bellman Errors 1 Max        8.97737e+06
trainer/Bellman Errors 1 Min        0.181264
trainer/Bellman Errors 2 Mean   78901.5
trainer/Bellman Errors 2 Std   498173
trainer/Bellman Errors 2 Max        7.76804e+06
trainer/Bellman Errors 2 Min        0.214819
trainer/Policy Action Mean          0.285659
trainer/Policy Action Std           0.782659
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     32000
exploration/num paths total      1195
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.980385
exploration/Rewards Std             0.113531
exploration/Rewards Max             1.27728
exploration/Rewards Min             0.254178
exploration/Returns Mean          980.385
exploration/Returns Std             0
exploration/Returns Max           980.385
exploration/Returns Min           980.385
exploration/Actions Mean            0.396237
exploration/Actions Std             0.568027
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       980.385
evaluation/num steps total     154008
evaluation/num paths total       5938
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.979035
evaluation/Rewards Std              0.119791
evaluation/Rewards Max              1.33762
evaluation/Rewards Min              0.204841
evaluation/Returns Mean           979.035
evaluation/Returns Std              1.94667
evaluation/Returns Max            981.07
evaluation/Returns Min            975.818
evaluation/Actions Mean             0.400683
evaluation/Actions Std              0.562871
evaluation/Actions Max              1
evaluation/Actions Min             -0.990194
evaluation/Num Paths                5
evaluation/Average Returns        979.035
time/data storing (s)               0.00338977
time/evaluation sampling (s)        1.82225
time/exploration sampling (s)       0.382448
time/logging (s)                    0.0102487
time/saving (s)                     0.00352453
time/training (s)                   3.61443
time/epoch (s)                      5.83629
time/total (s)                    184.236
Epoch                              30
-----------------------------  ----------------
2021-07-02 23:31:52.459287 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 31 finished
-----------------------------  ----------------
replay_buffer/size              33000
trainer/QF1 Loss                63857.9
trainer/QF2 Loss                63299.1
trainer/Policy Loss            -11008.5
trainer/Q1 Predictions Mean     10349.9
trainer/Q1 Predictions Std       6290.38
trainer/Q1 Predictions Max      17561.4
trainer/Q1 Predictions Min       -209.531
trainer/Q2 Predictions Mean     10370.6
trainer/Q2 Predictions Std       6286.02
trainer/Q2 Predictions Max      17523
trainer/Q2 Predictions Min       -164.959
trainer/Q Targets Mean          10357
trainer/Q Targets Std            6309.36
trainer/Q Targets Max           17563.8
trainer/Q Targets Min            -186.51
trainer/Bellman Errors 1 Mean   63857.9
trainer/Bellman Errors 1 Std   283316
trainer/Bellman Errors 1 Max        4.18462e+06
trainer/Bellman Errors 1 Min        0.79844
trainer/Bellman Errors 2 Mean   63299.1
trainer/Bellman Errors 2 Std   310980
trainer/Bellman Errors 2 Max        4.61755e+06
trainer/Bellman Errors 2 Min        0.182733
trainer/Policy Action Mean          0.21336
trainer/Policy Action Std           0.719362
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     33000
exploration/num paths total      1196
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.980172
exploration/Rewards Std             0.0951906
exploration/Rewards Max             1.09522
exploration/Rewards Min             0.266594
exploration/Returns Mean          980.172
exploration/Returns Std             0
exploration/Returns Max           980.172
exploration/Returns Min           980.172
exploration/Actions Mean            0.408056
exploration/Actions Std             0.486284
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       980.172
evaluation/num steps total     159008
evaluation/num paths total       5943
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.979727
evaluation/Rewards Std              0.102731
evaluation/Rewards Max              1.27638
evaluation/Rewards Min              0.214629
evaluation/Returns Mean           979.727
evaluation/Returns Std              0.566489
evaluation/Returns Max            980.437
evaluation/Returns Min            979.002
evaluation/Actions Mean             0.424276
evaluation/Actions Std              0.478075
evaluation/Actions Max              0.99832
evaluation/Actions Min             -0.971674
evaluation/Num Paths                5
evaluation/Average Returns        979.727
time/data storing (s)               0.00339546
time/evaluation sampling (s)        1.83452
time/exploration sampling (s)       0.384689
time/logging (s)                    0.010163
time/saving (s)                     0.0036672
time/training (s)                   3.6402
time/epoch (s)                      5.87664
time/total (s)                    190.116
Epoch                              31
-----------------------------  ----------------
2021-07-02 23:31:58.396242 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 32 finished
-----------------------------  ----------------
replay_buffer/size              34000
trainer/QF1 Loss                51053.3
trainer/QF2 Loss                49619.2
trainer/Policy Loss            -11008.5
trainer/Q1 Predictions Mean     10319.5
trainer/Q1 Predictions Std       6108.44
trainer/Q1 Predictions Max      17439.1
trainer/Q1 Predictions Min       -190.141
trainer/Q2 Predictions Mean     10282.4
trainer/Q2 Predictions Std       6104.08
trainer/Q2 Predictions Max      17439.2
trainer/Q2 Predictions Min       -176.688
trainer/Q Targets Mean          10301.2
trainer/Q Targets Std            6108.25
trainer/Q Targets Max           17390.8
trainer/Q Targets Min            -218.264
trainer/Bellman Errors 1 Mean   51053.3
trainer/Bellman Errors 1 Std   222929
trainer/Bellman Errors 1 Max        3.34865e+06
trainer/Bellman Errors 1 Min        0.169834
trainer/Bellman Errors 2 Mean   49619.2
trainer/Bellman Errors 2 Std   211308
trainer/Bellman Errors 2 Max        3.12147e+06
trainer/Bellman Errors 2 Min        0.0634804
trainer/Policy Action Mean          0.207363
trainer/Policy Action Std           0.743907
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     34000
exploration/num paths total      1197
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.977039
exploration/Rewards Std             0.105695
exploration/Rewards Max             1.1584
exploration/Rewards Min             0.211325
exploration/Returns Mean          977.039
exploration/Returns Std             0
exploration/Returns Max           977.039
exploration/Returns Min           977.039
exploration/Actions Mean            0.443851
exploration/Actions Std             0.550169
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       977.039
evaluation/num steps total     164008
evaluation/num paths total       5948
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.975811
evaluation/Rewards Std              0.113459
evaluation/Rewards Max              1.18017
evaluation/Rewards Min              0.18902
evaluation/Returns Mean           975.811
evaluation/Returns Std              0.532815
evaluation/Returns Max            976.392
evaluation/Returns Min            975.132
evaluation/Actions Mean             0.450854
evaluation/Actions Std              0.561253
evaluation/Actions Max              0.971458
evaluation/Actions Min             -0.883208
evaluation/Num Paths                5
evaluation/Average Returns        975.811
time/data storing (s)               0.00344565
time/evaluation sampling (s)        1.85522
time/exploration sampling (s)       0.379615
time/logging (s)                    0.00988166
time/saving (s)                     0.00366091
time/training (s)                   3.6816
time/epoch (s)                      5.93342
time/total (s)                    196.052
Epoch                              32
-----------------------------  ----------------
2021-07-02 23:32:04.285875 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 33 finished
-----------------------------  ----------------
replay_buffer/size              35000
trainer/QF1 Loss                77913.4
trainer/QF2 Loss                78712
trainer/Policy Loss            -10788.9
trainer/Q1 Predictions Mean      9926.85
trainer/Q1 Predictions Std       6172.1
trainer/Q1 Predictions Max      17448.9
trainer/Q1 Predictions Min       -198.945
trainer/Q2 Predictions Mean      9946.75
trainer/Q2 Predictions Std       6172.32
trainer/Q2 Predictions Max      17359.6
trainer/Q2 Predictions Min       -181.636
trainer/Q Targets Mean           9882.8
trainer/Q Targets Std            6162.28
trainer/Q Targets Max           17218.8
trainer/Q Targets Min            -258.09
trainer/Bellman Errors 1 Mean   77913.4
trainer/Bellman Errors 1 Std   325459
trainer/Bellman Errors 1 Max        3.23858e+06
trainer/Bellman Errors 1 Min        0.184016
trainer/Bellman Errors 2 Mean   78712
trainer/Bellman Errors 2 Std   332126
trainer/Bellman Errors 2 Max        3.47072e+06
trainer/Bellman Errors 2 Min        0.127331
trainer/Policy Action Mean          0.247822
trainer/Policy Action Std           0.706378
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     35000
exploration/num paths total      1198
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.975336
exploration/Rewards Std             0.079523
exploration/Rewards Max             1.06251
exploration/Rewards Min             0.458791
exploration/Returns Mean          975.336
exploration/Returns Std             0
exploration/Returns Max           975.336
exploration/Returns Min           975.336
exploration/Actions Mean            0.339306
exploration/Actions Std             0.443847
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       975.336
evaluation/num steps total     169008
evaluation/num paths total       5953
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.976592
evaluation/Rewards Std              0.0812884
evaluation/Rewards Max              1.0128
evaluation/Rewards Min              0.345385
evaluation/Returns Mean           976.592
evaluation/Returns Std              0.703844
evaluation/Returns Max            977.711
evaluation/Returns Min            975.884
evaluation/Actions Mean             0.339695
evaluation/Actions Std              0.410329
evaluation/Actions Max              0.9405
evaluation/Actions Min             -0.864187
evaluation/Num Paths                5
evaluation/Average Returns        976.592
time/data storing (s)               0.00343884
time/evaluation sampling (s)        1.83435
time/exploration sampling (s)       0.385099
time/logging (s)                    0.0100275
time/saving (s)                     0.00364292
time/training (s)                   3.65001
time/epoch (s)                      5.88656
time/total (s)                    201.941
Epoch                              33
-----------------------------  ----------------
2021-07-02 23:32:10.145351 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 34 finished
-----------------------------  ----------------
replay_buffer/size              36000
trainer/QF1 Loss               270956
trainer/QF2 Loss               273814
trainer/Policy Loss            -10710.7
trainer/Q1 Predictions Mean      9869.77
trainer/Q1 Predictions Std       5838.41
trainer/Q1 Predictions Max      17338.2
trainer/Q1 Predictions Min       -182.045
trainer/Q2 Predictions Mean      9849.9
trainer/Q2 Predictions Std       5823.15
trainer/Q2 Predictions Max      17234.1
trainer/Q2 Predictions Min       -179.389
trainer/Q Targets Mean           9835.32
trainer/Q Targets Std            5837.07
trainer/Q Targets Max           17362.7
trainer/Q Targets Min            -218.799
trainer/Bellman Errors 1 Mean  270956
trainer/Bellman Errors 1 Std        3.4281e+06
trainer/Bellman Errors 1 Max        5.49529e+07
trainer/Bellman Errors 1 Min        0.00145054
trainer/Bellman Errors 2 Mean  273814
trainer/Bellman Errors 2 Std        3.49220e+06
trainer/Bellman Errors 2 Max        5.59816e+07
trainer/Bellman Errors 2 Min        0.884408
trainer/Policy Action Mean          0.327392
trainer/Policy Action Std           0.71214
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     36000
exploration/num paths total      1199
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.979367
exploration/Rewards Std             0.0923786
exploration/Rewards Max             1.15592
exploration/Rewards Min             0.589557
exploration/Returns Mean          979.367
exploration/Returns Std             0
exploration/Returns Max           979.367
exploration/Returns Min           979.367
exploration/Actions Mean            0.187916
exploration/Actions Std             0.499798
exploration/Actions Max             1
exploration/Actions Min            -0.994887
exploration/Num Paths               1
exploration/Average Returns       979.367
evaluation/num steps total     174008
evaluation/num paths total       5958
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.980656
evaluation/Rewards Std              0.0987244
evaluation/Rewards Max              1.28866
evaluation/Rewards Min              0.562423
evaluation/Returns Mean           980.656
evaluation/Returns Std              0.6703
evaluation/Returns Max            981.716
evaluation/Returns Min            979.89
evaluation/Actions Mean             0.20043
evaluation/Actions Std              0.492039
evaluation/Actions Max              0.999981
evaluation/Actions Min             -0.976128
evaluation/Num Paths                5
evaluation/Average Returns        980.656
time/data storing (s)               0.00340919
time/evaluation sampling (s)        1.82299
time/exploration sampling (s)       0.383505
time/logging (s)                    0.00987375
time/saving (s)                     0.00352888
time/training (s)                   3.63275
time/epoch (s)                      5.85605
time/total (s)                    207.8
Epoch                              34
-----------------------------  ----------------
2021-07-02 23:32:16.039420 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 35 finished
-----------------------------  ----------------
replay_buffer/size              37000
trainer/QF1 Loss               121294
trainer/QF2 Loss               109943
trainer/Policy Loss            -11379.5
trainer/Q1 Predictions Mean     10562.4
trainer/Q1 Predictions Std       5434.05
trainer/Q1 Predictions Max      17527.2
trainer/Q1 Predictions Min       -243.671
trainer/Q2 Predictions Mean     10546.8
trainer/Q2 Predictions Std       5427.16
trainer/Q2 Predictions Max      17137
trainer/Q2 Predictions Min       -222.276
trainer/Q Targets Mean          10541.9
trainer/Q Targets Std            5388.58
trainer/Q Targets Max           16995.6
trainer/Q Targets Min            -293.836
trainer/Bellman Errors 1 Mean  121294
trainer/Bellman Errors 1 Std   595640
trainer/Bellman Errors 1 Max        6.4683e+06
trainer/Bellman Errors 1 Min        0.0644684
trainer/Bellman Errors 2 Mean  109943
trainer/Bellman Errors 2 Std   479735
trainer/Bellman Errors 2 Max        5.72258e+06
trainer/Bellman Errors 2 Min        0.613407
trainer/Policy Action Mean          0.437625
trainer/Policy Action Std           0.756156
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     37000
exploration/num paths total      1201
exploration/path length Mean      500
exploration/path length Std       296
exploration/path length Max       796
exploration/path length Min       204
exploration/Rewards Mean            1.10073
exploration/Rewards Std             0.273432
exploration/Rewards Max             1.67818
exploration/Rewards Min             0.431845
exploration/Returns Mean          550.364
exploration/Returns Std           332.598
exploration/Returns Max           882.962
exploration/Returns Min           217.766
exploration/Actions Mean            0.100637
exploration/Actions Std             0.585603
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       550.364
evaluation/num steps total     178421
evaluation/num paths total       5965
evaluation/path length Mean       630.429
evaluation/path length Std        191.893
evaluation/path length Max       1000
evaluation/path length Min        389
evaluation/Rewards Mean             1.12189
evaluation/Rewards Std              0.300665
evaluation/Rewards Max              1.71384
evaluation/Rewards Min              0.28573
evaluation/Returns Mean           707.271
evaluation/Returns Std            182.392
evaluation/Returns Max           1038.76
evaluation/Returns Min            463.242
evaluation/Actions Mean             0.10702
evaluation/Actions Std              0.56771
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths                7
evaluation/Average Returns        707.271
time/data storing (s)               0.0035674
time/evaluation sampling (s)        1.85691
time/exploration sampling (s)       0.39705
time/logging (s)                    0.00894532
time/saving (s)                     0.00353503
time/training (s)                   3.61989
time/epoch (s)                      5.88989
time/total (s)                    213.693
Epoch                              35
-----------------------------  ----------------
2021-07-02 23:32:21.900729 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 36 finished
-----------------------------  ----------------
replay_buffer/size              38000
trainer/QF1 Loss               540814
trainer/QF2 Loss               537159
trainer/Policy Loss            -11113.8
trainer/Q1 Predictions Mean     10426.7
trainer/Q1 Predictions Std       5414.2
trainer/Q1 Predictions Max      17101.2
trainer/Q1 Predictions Min       -200.394
trainer/Q2 Predictions Mean     10427.8
trainer/Q2 Predictions Std       5417.04
trainer/Q2 Predictions Max      17166.2
trainer/Q2 Predictions Min       -185.04
trainer/Q Targets Mean          10406
trainer/Q Targets Std            5465.57
trainer/Q Targets Max           17078.2
trainer/Q Targets Min            -243.815
trainer/Bellman Errors 1 Mean  540814
trainer/Bellman Errors 1 Std        7.6008e+06
trainer/Bellman Errors 1 Max        1.21834e+08
trainer/Bellman Errors 1 Min        0.00151755
trainer/Bellman Errors 2 Mean  537159
trainer/Bellman Errors 2 Std        7.367e+06
trainer/Bellman Errors 2 Max        1.18043e+08
trainer/Bellman Errors 2 Min        0.284314
trainer/Policy Action Mean          0.535696
trainer/Policy Action Std           0.712769
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     38000
exploration/num paths total      1208
exploration/path length Mean      142.857
exploration/path length Std        55.6556
exploration/path length Max       193
exploration/path length Min        10
exploration/Rewards Mean            1.58935
exploration/Rewards Std             0.294556
exploration/Rewards Max             2.16387
exploration/Rewards Min             1.01173
exploration/Returns Mean          227.05
exploration/Returns Std            89.0619
exploration/Returns Max           291.373
exploration/Returns Min            11.0569
exploration/Actions Mean            0.318146
exploration/Actions Std             0.533533
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               7
exploration/Average Returns       227.05
evaluation/num steps total     183285
evaluation/num paths total       5993
evaluation/path length Mean       173.714
evaluation/path length Std         15.487
evaluation/path length Max        213
evaluation/path length Min        158
evaluation/Rewards Mean             1.56079
evaluation/Rewards Std              0.280107
evaluation/Rewards Max              2.1646
evaluation/Rewards Min              1.00862
evaluation/Returns Mean           271.132
evaluation/Returns Std             14.9336
evaluation/Returns Max            309.571
evaluation/Returns Min            256.245
evaluation/Actions Mean             0.294073
evaluation/Actions Std              0.515777
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.997919
evaluation/Num Paths               28
evaluation/Average Returns        271.132
time/data storing (s)               0.00348412
time/evaluation sampling (s)        1.82192
time/exploration sampling (s)       0.376699
time/logging (s)                    0.00980727
time/saving (s)                     0.00350795
time/training (s)                   3.64376
time/epoch (s)                      5.85918
time/total (s)                    219.555
Epoch                              36
-----------------------------  ----------------
2021-07-02 23:32:27.736364 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 37 finished
-----------------------------  ----------------
replay_buffer/size              39000
trainer/QF1 Loss               168695
trainer/QF2 Loss               171406
trainer/Policy Loss            -10703.7
trainer/Q1 Predictions Mean      9918.05
trainer/Q1 Predictions Std       5530.59
trainer/Q1 Predictions Max      18459.7
trainer/Q1 Predictions Min       -142.181
trainer/Q2 Predictions Mean      9890.31
trainer/Q2 Predictions Std       5529.72
trainer/Q2 Predictions Max      18234.1
trainer/Q2 Predictions Min       -140.31
trainer/Q Targets Mean           9907.31
trainer/Q Targets Std            5531.48
trainer/Q Targets Max           17628
trainer/Q Targets Min            -174.695
trainer/Bellman Errors 1 Mean  168695
trainer/Bellman Errors 1 Std        1.14275e+06
trainer/Bellman Errors 1 Max        1.67465e+07
trainer/Bellman Errors 1 Min        0.0139627
trainer/Bellman Errors 2 Mean  171406
trainer/Bellman Errors 2 Std        1.13889e+06
trainer/Bellman Errors 2 Max        1.67486e+07
trainer/Bellman Errors 2 Min        0.25
trainer/Policy Action Mean          0.475611
trainer/Policy Action Std           0.734177
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     39000
exploration/num paths total      1211
exploration/path length Mean      333.333
exploration/path length Std       142.701
exploration/path length Max       492
exploration/path length Min       146
exploration/Rewards Mean            1.21716
exploration/Rewards Std             0.30117
exploration/Rewards Max             2.18541
exploration/Rewards Min             0.844362
exploration/Returns Mean          405.718
exploration/Returns Std           176.364
exploration/Returns Max           590.608
exploration/Returns Min           168.297
exploration/Actions Mean            0.0879517
exploration/Actions Std             0.496447
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               3
exploration/Average Returns       405.718
evaluation/num steps total     187932
evaluation/num paths total       5999
evaluation/path length Mean       774.5
evaluation/path length Std        185.949
evaluation/path length Max       1000
evaluation/path length Min        498
evaluation/Rewards Mean             1.11493
evaluation/Rewards Std              0.257444
evaluation/Rewards Max              2.19421
evaluation/Rewards Min              0.759388
evaluation/Returns Mean           863.513
evaluation/Returns Std            175.094
evaluation/Returns Max           1031.64
evaluation/Returns Min            595.377
evaluation/Actions Mean             0.061583
evaluation/Actions Std              0.497855
evaluation/Actions Max              0.999837
evaluation/Actions Min             -0.999811
evaluation/Num Paths                6
evaluation/Average Returns        863.513
time/data storing (s)               0.00340818
time/evaluation sampling (s)        1.80563
time/exploration sampling (s)       0.379877
time/logging (s)                    0.00933208
time/saving (s)                     0.00351456
time/training (s)                   3.63039
time/epoch (s)                      5.83216
time/total (s)                    225.389
Epoch                              37
-----------------------------  ----------------
2021-07-02 23:32:33.566361 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 38 finished
-----------------------------  ----------------
replay_buffer/size              40000
trainer/QF1 Loss               169530
trainer/QF2 Loss               171488
trainer/Policy Loss            -10695.3
trainer/Q1 Predictions Mean      9844.91
trainer/Q1 Predictions Std       5563.61
trainer/Q1 Predictions Max      16464.3
trainer/Q1 Predictions Min       -169.022
trainer/Q2 Predictions Mean      9831.4
trainer/Q2 Predictions Std       5555.32
trainer/Q2 Predictions Max      16633.5
trainer/Q2 Predictions Min       -164.614
trainer/Q Targets Mean           9790.48
trainer/Q Targets Std            5586.87
trainer/Q Targets Max           16494.7
trainer/Q Targets Min            -209.728
trainer/Bellman Errors 1 Mean  169530
trainer/Bellman Errors 1 Std        1.46193e+06
trainer/Bellman Errors 1 Max        1.83766e+07
trainer/Bellman Errors 1 Min        0.990258
trainer/Bellman Errors 2 Mean  171488
trainer/Bellman Errors 2 Std        1.49223e+06
trainer/Bellman Errors 2 Max        2.05574e+07
trainer/Bellman Errors 2 Min        0.000504494
trainer/Policy Action Mean          0.443937
trainer/Policy Action Std           0.736173
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     40000
exploration/num paths total      1212
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            1.0071
exploration/Rewards Std             0.117089
exploration/Rewards Max             1.2895
exploration/Rewards Min             0.647948
exploration/Returns Mean         1007.1
exploration/Returns Std             0
exploration/Returns Max          1007.1
exploration/Returns Min          1007.1
exploration/Actions Mean            0.0884343
exploration/Actions Std             0.583948
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns      1007.1
evaluation/num steps total     192932
evaluation/num paths total       6004
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             1.00859
evaluation/Rewards Std              0.113368
evaluation/Rewards Max              1.37697
evaluation/Rewards Min              0.707462
evaluation/Returns Mean          1008.59
evaluation/Returns Std              1.55445
evaluation/Returns Max           1011.34
evaluation/Returns Min           1006.88
evaluation/Actions Mean             0.0822348
evaluation/Actions Std              0.590801
evaluation/Actions Max              0.999871
evaluation/Actions Min             -0.999967
evaluation/Num Paths                5
evaluation/Average Returns       1008.59
time/data storing (s)               0.0034083
time/evaluation sampling (s)        1.81538
time/exploration sampling (s)       0.381971
time/logging (s)                    0.0100026
time/saving (s)                     0.00366007
time/training (s)                   3.61299
time/epoch (s)                      5.82742
time/total (s)                    231.219
Epoch                              38
-----------------------------  ----------------
2021-07-02 23:32:39.647077 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 39 finished
-----------------------------  ---------------
replay_buffer/size              41000
trainer/QF1 Loss                36939.8
trainer/QF2 Loss                40544.4
trainer/Policy Loss            -10394.6
trainer/Q1 Predictions Mean      9820.52
trainer/Q1 Predictions Std       5435.88
trainer/Q1 Predictions Max      15811.6
trainer/Q1 Predictions Min       -139.883
trainer/Q2 Predictions Mean      9835.98
trainer/Q2 Predictions Std       5445.64
trainer/Q2 Predictions Max      15938
trainer/Q2 Predictions Min       -132.225
trainer/Q Targets Mean           9846.4
trainer/Q Targets Std            5434.65
trainer/Q Targets Max           15756.9
trainer/Q Targets Min            -183.985
trainer/Bellman Errors 1 Mean   36939.8
trainer/Bellman Errors 1 Std    80856.2
trainer/Bellman Errors 1 Max   741701
trainer/Bellman Errors 1 Min        0.894265
trainer/Bellman Errors 2 Mean   40544.4
trainer/Bellman Errors 2 Std    90253.9
trainer/Bellman Errors 2 Max   829642
trainer/Bellman Errors 2 Min        0.0558366
trainer/Policy Action Mean          0.448507
trainer/Policy Action Std           0.729842
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     41000
exploration/num paths total      1213
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.9957
exploration/Rewards Std             0.0518971
exploration/Rewards Max             1.1478
exploration/Rewards Min             0.817939
exploration/Returns Mean          995.7
exploration/Returns Std             0
exploration/Returns Max           995.7
exploration/Returns Min           995.7
exploration/Actions Mean            0.11017
exploration/Actions Std             0.544147
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       995.7
evaluation/num steps total     197932
evaluation/num paths total       6009
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.995392
evaluation/Rewards Std              0.0426879
evaluation/Rewards Max              1.1656
evaluation/Rewards Min              0.864591
evaluation/Returns Mean           995.392
evaluation/Returns Std              0.861544
evaluation/Returns Max            996.686
evaluation/Returns Min            994.217
evaluation/Actions Mean             0.110438
evaluation/Actions Std              0.550461
evaluation/Actions Max              0.999773
evaluation/Actions Min             -0.999388
evaluation/Num Paths                5
evaluation/Average Returns        995.392
time/data storing (s)               0.0038459
time/evaluation sampling (s)        1.90442
time/exploration sampling (s)       0.463803
time/logging (s)                    0.0100565
time/saving (s)                     0.00356091
time/training (s)                   3.69148
time/epoch (s)                      6.07717
time/total (s)                    237.3
Epoch                              39
-----------------------------  ---------------
2021-07-02 23:32:45.551079 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 40 finished
-----------------------------  ----------------
replay_buffer/size              42000
trainer/QF1 Loss                71883.2
trainer/QF2 Loss                71185.6
trainer/Policy Loss            -10977.7
trainer/Q1 Predictions Mean     10343.4
trainer/Q1 Predictions Std       4710.51
trainer/Q1 Predictions Max      15797.1
trainer/Q1 Predictions Min       -100.025
trainer/Q2 Predictions Mean     10370.5
trainer/Q2 Predictions Std       4708.8
trainer/Q2 Predictions Max      15960.4
trainer/Q2 Predictions Min       -117.039
trainer/Q Targets Mean          10356.7
trainer/Q Targets Std            4721.63
trainer/Q Targets Max           15950.4
trainer/Q Targets Min            -112.234
trainer/Bellman Errors 1 Mean   71883.2
trainer/Bellman Errors 1 Std   404574
trainer/Bellman Errors 1 Max        6.31427e+06
trainer/Bellman Errors 1 Min        0.0223246
trainer/Bellman Errors 2 Mean   71185.6
trainer/Bellman Errors 2 Std   437248
trainer/Bellman Errors 2 Max        6.90779e+06
trainer/Bellman Errors 2 Min        1.35959
trainer/Policy Action Mean          0.242387
trainer/Policy Action Std           0.754065
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     42000
exploration/num paths total      1214
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.98664
exploration/Rewards Std             0.0581898
exploration/Rewards Max             1.15624
exploration/Rewards Min             0.738216
exploration/Returns Mean          986.64
exploration/Returns Std             0
exploration/Returns Max           986.64
exploration/Returns Min           986.64
exploration/Actions Mean            0.144573
exploration/Actions Std             0.336101
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       986.64
evaluation/num steps total     202932
evaluation/num paths total       6014
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.986123
evaluation/Rewards Std              0.0545589
evaluation/Rewards Max              1.22
evaluation/Rewards Min              0.76181
evaluation/Returns Mean           986.123
evaluation/Returns Std              0.467335
evaluation/Returns Max            986.983
evaluation/Returns Min            985.633
evaluation/Actions Mean             0.156863
evaluation/Actions Std              0.310103
evaluation/Actions Max              0.985537
evaluation/Actions Min             -0.999757
evaluation/Num Paths                5
evaluation/Average Returns        986.123
time/data storing (s)               0.00339763
time/evaluation sampling (s)        1.83158
time/exploration sampling (s)       0.39496
time/logging (s)                    0.0101563
time/saving (s)                     0.0037102
time/training (s)                   3.65701
time/epoch (s)                      5.90081
time/total (s)                    243.203
Epoch                              40
-----------------------------  ----------------
2021-07-02 23:32:51.442347 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 41 finished
-----------------------------  ----------------
replay_buffer/size              43000
trainer/QF1 Loss                38072.8
trainer/QF2 Loss                41877.2
trainer/Policy Loss            -10869.6
trainer/Q1 Predictions Mean     10356
trainer/Q1 Predictions Std       4860.16
trainer/Q1 Predictions Max      17019
trainer/Q1 Predictions Min       -119.944
trainer/Q2 Predictions Mean     10365.8
trainer/Q2 Predictions Std       4865.8
trainer/Q2 Predictions Max      16808.2
trainer/Q2 Predictions Min       -127.511
trainer/Q Targets Mean          10346.4
trainer/Q Targets Std            4846.21
trainer/Q Targets Max           16729.9
trainer/Q Targets Min            -120.087
trainer/Bellman Errors 1 Mean   38072.8
trainer/Bellman Errors 1 Std   129471
trainer/Bellman Errors 1 Max        1.84408e+06
trainer/Bellman Errors 1 Min        0.0205226
trainer/Bellman Errors 2 Mean   41877.2
trainer/Bellman Errors 2 Std   160776
trainer/Bellman Errors 2 Max        2.36238e+06
trainer/Bellman Errors 2 Min        0.130929
trainer/Policy Action Mean          0.370718
trainer/Policy Action Std           0.683775
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     43000
exploration/num paths total      1215
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.992975
exploration/Rewards Std             0.0620521
exploration/Rewards Max             1.17655
exploration/Rewards Min             0.7982
exploration/Returns Mean          992.975
exploration/Returns Std             0
exploration/Returns Max           992.975
exploration/Returns Min           992.975
exploration/Actions Mean            0.15522
exploration/Actions Std             0.351588
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       992.975
evaluation/num steps total     207932
evaluation/num paths total       6019
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.993778
evaluation/Rewards Std              0.0608258
evaluation/Rewards Max              1.15546
evaluation/Rewards Min              0.725433
evaluation/Returns Mean           993.778
evaluation/Returns Std              0.580599
evaluation/Returns Max            994.699
evaluation/Returns Min            993.034
evaluation/Actions Mean             0.155441
evaluation/Actions Std              0.301372
evaluation/Actions Max              0.995227
evaluation/Actions Min             -0.995102
evaluation/Num Paths                5
evaluation/Average Returns        993.778
time/data storing (s)               0.003416
time/evaluation sampling (s)        1.86722
time/exploration sampling (s)       0.380588
time/logging (s)                    0.00998288
time/saving (s)                     0.00356593
time/training (s)                   3.62279
time/epoch (s)                      5.88756
time/total (s)                    249.094
Epoch                              41
-----------------------------  ----------------
2021-07-02 23:32:57.360855 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 42 finished
-----------------------------  ----------------
replay_buffer/size              44000
trainer/QF1 Loss               379098
trainer/QF2 Loss               370556
trainer/Policy Loss            -10874
trainer/Q1 Predictions Mean     10178.6
trainer/Q1 Predictions Std       4775.78
trainer/Q1 Predictions Max      15810.9
trainer/Q1 Predictions Min       -154.798
trainer/Q2 Predictions Mean     10176.6
trainer/Q2 Predictions Std       4778.58
trainer/Q2 Predictions Max      15779.2
trainer/Q2 Predictions Min       -188.058
trainer/Q Targets Mean          10089.1
trainer/Q Targets Std            4806.03
trainer/Q Targets Max           15720.3
trainer/Q Targets Min            -129.484
trainer/Bellman Errors 1 Mean  379098
trainer/Bellman Errors 1 Std        4.88555e+06
trainer/Bellman Errors 1 Max        7.81986e+07
trainer/Bellman Errors 1 Min        0.605783
trainer/Bellman Errors 2 Mean  370556
trainer/Bellman Errors 2 Std        4.87744e+06
trainer/Bellman Errors 2 Max        7.80963e+07
trainer/Bellman Errors 2 Min        2.5183
trainer/Policy Action Mean          0.297071
trainer/Policy Action Std           0.709328
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     44000
exploration/num paths total      1216
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.985514
exploration/Rewards Std             0.0980513
exploration/Rewards Max             1.22965
exploration/Rewards Min             0.693514
exploration/Returns Mean          985.514
exploration/Returns Std             0
exploration/Returns Max           985.514
exploration/Returns Min           985.514
exploration/Actions Mean            0.11574
exploration/Actions Std             0.374304
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       985.514
evaluation/num steps total     212932
evaluation/num paths total       6024
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.98669
evaluation/Rewards Std              0.0922192
evaluation/Rewards Max              1.28362
evaluation/Rewards Min              0.674248
evaluation/Returns Mean           986.69
evaluation/Returns Std              0.949389
evaluation/Returns Max            988.538
evaluation/Returns Min            985.953
evaluation/Actions Mean             0.112159
evaluation/Actions Std              0.360394
evaluation/Actions Max              0.997353
evaluation/Actions Min             -0.999955
evaluation/Num Paths                5
evaluation/Average Returns        986.69
time/data storing (s)               0.00336787
time/evaluation sampling (s)        1.87585
time/exploration sampling (s)       0.397778
time/logging (s)                    0.0101146
time/saving (s)                     0.0035131
time/training (s)                   3.62475
time/epoch (s)                      5.91537
time/total (s)                    255.012
Epoch                              42
-----------------------------  ----------------
2021-07-02 23:33:03.209743 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 43 finished
-----------------------------  ---------------
replay_buffer/size              45000
trainer/QF1 Loss                32564.6
trainer/QF2 Loss                35634.6
trainer/Policy Loss            -10633.8
trainer/Q1 Predictions Mean      9989.04
trainer/Q1 Predictions Std       4895.45
trainer/Q1 Predictions Max      16624.5
trainer/Q1 Predictions Min       -134.144
trainer/Q2 Predictions Mean      9984.32
trainer/Q2 Predictions Std       4883.01
trainer/Q2 Predictions Max      16673.1
trainer/Q2 Predictions Min       -133.103
trainer/Q Targets Mean           9997.9
trainer/Q Targets Std            4913.43
trainer/Q Targets Max           16677.8
trainer/Q Targets Min            -142.98
trainer/Bellman Errors 1 Mean   32564.6
trainer/Bellman Errors 1 Std    57147.8
trainer/Bellman Errors 1 Max   390021
trainer/Bellman Errors 1 Min        1.53334
trainer/Bellman Errors 2 Mean   35634.6
trainer/Bellman Errors 2 Std    69864.4
trainer/Bellman Errors 2 Max   457504
trainer/Bellman Errors 2 Min        0.0103817
trainer/Policy Action Mean          0.341679
trainer/Policy Action Std           0.71907
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     45000
exploration/num paths total      1217
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.986331
exploration/Rewards Std             0.103524
exploration/Rewards Max             1.24892
exploration/Rewards Min             0.685866
exploration/Returns Mean          986.331
exploration/Returns Std             0
exploration/Returns Max           986.331
exploration/Returns Min           986.331
exploration/Actions Mean            0.209988
exploration/Actions Std             0.448619
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       986.331
evaluation/num steps total     217932
evaluation/num paths total       6029
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.9867
evaluation/Rewards Std              0.111264
evaluation/Rewards Max              1.29683
evaluation/Rewards Min              0.622554
evaluation/Returns Mean           986.7
evaluation/Returns Std              0.987702
evaluation/Returns Max            988.404
evaluation/Returns Min            985.779
evaluation/Actions Mean             0.206033
evaluation/Actions Std              0.415007
evaluation/Actions Max              1
evaluation/Actions Min             -0.999999
evaluation/Num Paths                5
evaluation/Average Returns        986.7
time/data storing (s)               0.00343203
time/evaluation sampling (s)        1.81141
time/exploration sampling (s)       0.38168
time/logging (s)                    0.0103112
time/saving (s)                     0.00355002
time/training (s)                   3.63542
time/epoch (s)                      5.8458
time/total (s)                    260.861
Epoch                              43
-----------------------------  ---------------
2021-07-02 23:33:09.025578 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 44 finished
-----------------------------  ----------------
replay_buffer/size              46000
trainer/QF1 Loss                93909.3
trainer/QF2 Loss               104115
trainer/Policy Loss            -10516.5
trainer/Q1 Predictions Mean      9952.72
trainer/Q1 Predictions Std       4830.39
trainer/Q1 Predictions Max      16961.1
trainer/Q1 Predictions Min       -142.082
trainer/Q2 Predictions Mean      9958.82
trainer/Q2 Predictions Std       4829.86
trainer/Q2 Predictions Max      16722
trainer/Q2 Predictions Min       -179.898
trainer/Q Targets Mean           9930.27
trainer/Q Targets Std            4865.66
trainer/Q Targets Max           16940.7
trainer/Q Targets Min            -153.712
trainer/Bellman Errors 1 Mean   93909.3
trainer/Bellman Errors 1 Std   783217
trainer/Bellman Errors 1 Max        1.19714e+07
trainer/Bellman Errors 1 Min        0.0109689
trainer/Bellman Errors 2 Mean  104115
trainer/Bellman Errors 2 Std   900635
trainer/Bellman Errors 2 Max        1.39956e+07
trainer/Bellman Errors 2 Min        1.03944
trainer/Policy Action Mean          0.366009
trainer/Policy Action Std           0.720143
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     46000
exploration/num paths total      1218
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.991207
exploration/Rewards Std             0.106093
exploration/Rewards Max             1.24994
exploration/Rewards Min             0.591537
exploration/Returns Mean          991.207
exploration/Returns Std             0
exploration/Returns Max           991.207
exploration/Returns Min           991.207
exploration/Actions Mean            0.203234
exploration/Actions Std             0.586627
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       991.207
evaluation/num steps total     222932
evaluation/num paths total       6034
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.993252
evaluation/Rewards Std              0.107397
evaluation/Rewards Max              1.31793
evaluation/Rewards Min              0.623709
evaluation/Returns Mean           993.252
evaluation/Returns Std              1.27687
evaluation/Returns Max            994.922
evaluation/Returns Min            990.966
evaluation/Actions Mean             0.20553
evaluation/Actions Std              0.575668
evaluation/Actions Max              1
evaluation/Actions Min             -0.998701
evaluation/Num Paths                5
evaluation/Average Returns        993.252
time/data storing (s)               0.00338832
time/evaluation sampling (s)        1.82007
time/exploration sampling (s)       0.381285
time/logging (s)                    0.0102975
time/saving (s)                     0.0035272
time/training (s)                   3.59369
time/epoch (s)                      5.81226
time/total (s)                    266.676
Epoch                              44
-----------------------------  ----------------
2021-07-02 23:33:14.899504 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 45 finished
-----------------------------  ----------------
replay_buffer/size              47000
trainer/QF1 Loss                38926.8
trainer/QF2 Loss                32289.5
trainer/Policy Loss            -10220.9
trainer/Q1 Predictions Mean      9683.24
trainer/Q1 Predictions Std       4927.8
trainer/Q1 Predictions Max      17681.4
trainer/Q1 Predictions Min       -151.338
trainer/Q2 Predictions Mean      9694.33
trainer/Q2 Predictions Std       4924.39
trainer/Q2 Predictions Max      17590
trainer/Q2 Predictions Min       -175.058
trainer/Q Targets Mean           9727.92
trainer/Q Targets Std            4935.86
trainer/Q Targets Max           17415.7
trainer/Q Targets Min            -147.051
trainer/Bellman Errors 1 Mean   38926.8
trainer/Bellman Errors 1 Std   109005
trainer/Bellman Errors 1 Max        1.19412e+06
trainer/Bellman Errors 1 Min        0.0253382
trainer/Bellman Errors 2 Mean   32289.5
trainer/Bellman Errors 2 Std    65399.3
trainer/Bellman Errors 2 Max   490633
trainer/Bellman Errors 2 Min        2.45975
trainer/Policy Action Mean          0.330859
trainer/Policy Action Std           0.777171
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     47000
exploration/num paths total      1225
exploration/path length Mean      142.857
exploration/path length Std        25.1818
exploration/path length Max       167
exploration/path length Min        86
exploration/Rewards Mean            0.81217
exploration/Rewards Std             0.240615
exploration/Rewards Max             1.58945
exploration/Rewards Min             0.222867
exploration/Returns Mean          116.024
exploration/Returns Std            20.2836
exploration/Returns Max           137.403
exploration/Returns Min            71.9336
exploration/Actions Mean            0.393749
exploration/Actions Std             0.586106
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               7
exploration/Average Returns       116.024
evaluation/num steps total     227884
evaluation/num paths total       6070
evaluation/path length Mean       137.556
evaluation/path length Std         21.7018
evaluation/path length Max        192
evaluation/path length Min        107
evaluation/Rewards Mean             0.791103
evaluation/Rewards Std              0.225582
evaluation/Rewards Max              1.45194
evaluation/Rewards Min              0.226614
evaluation/Returns Mean           108.821
evaluation/Returns Std             21.9637
evaluation/Returns Max            163.393
evaluation/Returns Min             78.4493
evaluation/Actions Mean             0.443173
evaluation/Actions Std              0.578361
evaluation/Actions Max              1
evaluation/Actions Min             -0.999509
evaluation/Num Paths               36
evaluation/Average Returns        108.821
time/data storing (s)               0.00346986
time/evaluation sampling (s)        1.82156
time/exploration sampling (s)       0.380591
time/logging (s)                    0.0100381
time/saving (s)                     0.00357499
time/training (s)                   3.65079
time/epoch (s)                      5.87002
time/total (s)                    272.549
Epoch                              45
-----------------------------  ----------------
2021-07-02 23:33:20.830410 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 46 finished
-----------------------------  ----------------
replay_buffer/size              48000
trainer/QF1 Loss                62151.3
trainer/QF2 Loss                76362.5
trainer/Policy Loss            -10807.5
trainer/Q1 Predictions Mean     10126
trainer/Q1 Predictions Std       4735.04
trainer/Q1 Predictions Max      19890.9
trainer/Q1 Predictions Min       -192.419
trainer/Q2 Predictions Mean     10119.2
trainer/Q2 Predictions Std       4738.45
trainer/Q2 Predictions Max      19726.8
trainer/Q2 Predictions Min       -194.117
trainer/Q Targets Mean          10130.1
trainer/Q Targets Std            4743.65
trainer/Q Targets Max           19501.5
trainer/Q Targets Min            -180.002
trainer/Bellman Errors 1 Mean   62151.3
trainer/Bellman Errors 1 Std   436119
trainer/Bellman Errors 1 Max        6.94225e+06
trainer/Bellman Errors 1 Min        8.96488
trainer/Bellman Errors 2 Mean   76362.5
trainer/Bellman Errors 2 Std   566645
trainer/Bellman Errors 2 Max        9.03961e+06
trainer/Bellman Errors 2 Min        0.116825
trainer/Policy Action Mean          0.33299
trainer/Policy Action Std           0.735443
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     48000
exploration/num paths total      1226
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.97312
exploration/Rewards Std             0.0928031
exploration/Rewards Max             1.45367
exploration/Rewards Min             0.516496
exploration/Returns Mean          973.12
exploration/Returns Std             0
exploration/Returns Max           973.12
exploration/Returns Min           973.12
exploration/Actions Mean            0.553405
exploration/Actions Std             0.613067
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       973.12
evaluation/num steps total     232884
evaluation/num paths total       6075
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.981955
evaluation/Rewards Std              0.126181
evaluation/Rewards Max              1.60247
evaluation/Rewards Min              0.478086
evaluation/Returns Mean           981.955
evaluation/Returns Std              9.80326
evaluation/Returns Max            994.484
evaluation/Returns Min            972.911
evaluation/Actions Mean             0.317512
evaluation/Actions Std              0.579357
evaluation/Actions Max              0.999993
evaluation/Actions Min             -0.999669
evaluation/Num Paths                5
evaluation/Average Returns        981.955
time/data storing (s)               0.00349461
time/evaluation sampling (s)        1.81508
time/exploration sampling (s)       0.406936
time/logging (s)                    0.00992564
time/saving (s)                     0.00372043
time/training (s)                   3.68839
time/epoch (s)                      5.92755
time/total (s)                    278.48
Epoch                              46
-----------------------------  ----------------
2021-07-02 23:33:26.701859 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 47 finished
-----------------------------  ----------------
replay_buffer/size              49000
trainer/QF1 Loss               206753
trainer/QF2 Loss               236301
trainer/Policy Loss            -10352.7
trainer/Q1 Predictions Mean      9825.51
trainer/Q1 Predictions Std       4707.64
trainer/Q1 Predictions Max      22579.5
trainer/Q1 Predictions Min       -230.307
trainer/Q2 Predictions Mean      9827.5
trainer/Q2 Predictions Std       4720.49
trainer/Q2 Predictions Max      24286.8
trainer/Q2 Predictions Min       -202.289
trainer/Q Targets Mean           9796.44
trainer/Q Targets Std            4702.2
trainer/Q Targets Max           21077.2
trainer/Q Targets Min            -179.983
trainer/Bellman Errors 1 Mean  206753
trainer/Bellman Errors 1 Std        2.05653e+06
trainer/Bellman Errors 1 Max        3.22969e+07
trainer/Bellman Errors 1 Min        0.030899
trainer/Bellman Errors 2 Mean  236301
trainer/Bellman Errors 2 Std        2.20344e+06
trainer/Bellman Errors 2 Max        3.31025e+07
trainer/Bellman Errors 2 Min        0.260858
trainer/Policy Action Mean          0.654493
trainer/Policy Action Std           0.606047
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     49000
exploration/num paths total      1273
exploration/path length Mean       21.2766
exploration/path length Std         2.19963
exploration/path length Max        23
exploration/path length Min         7
exploration/Rewards Mean            1.56847
exploration/Rewards Std             0.369726
exploration/Rewards Max             2.28842
exploration/Rewards Min             1.00691
exploration/Returns Mean           33.3716
exploration/Returns Std             3.95457
exploration/Returns Max            36.6967
exploration/Returns Min             7.70066
exploration/Actions Mean            0.468907
exploration/Actions Std             0.738624
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              47
exploration/Average Returns        33.3716
evaluation/num steps total     237870
evaluation/num paths total       6311
evaluation/path length Mean        21.1271
evaluation/path length Std          0.333106
evaluation/path length Max         22
evaluation/path length Min         21
evaluation/Rewards Mean             1.5697
evaluation/Rewards Std              0.369113
evaluation/Rewards Max              2.2977
evaluation/Rewards Min              1.00548
evaluation/Returns Mean            33.1632
evaluation/Returns Std              0.585829
evaluation/Returns Max             35.1878
evaluation/Returns Min             32.4081
evaluation/Actions Mean             0.472019
evaluation/Actions Std              0.763652
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths              236
evaluation/Average Returns         33.1632
time/data storing (s)               0.00344906
time/evaluation sampling (s)        1.85226
time/exploration sampling (s)       0.38442
time/logging (s)                    0.0121848
time/saving (s)                     0.00479519
time/training (s)                   3.61314
time/epoch (s)                      5.87024
time/total (s)                    284.353
Epoch                              47
-----------------------------  ----------------
2021-07-02 23:33:32.475469 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 48 finished
-----------------------------  ----------------
replay_buffer/size              50000
trainer/QF1 Loss               158819
trainer/QF2 Loss               157362
trainer/Policy Loss            -10672.8
trainer/Q1 Predictions Mean      9949.61
trainer/Q1 Predictions Std       5335.98
trainer/Q1 Predictions Max      21176.1
trainer/Q1 Predictions Min       -172.959
trainer/Q2 Predictions Mean      9950.21
trainer/Q2 Predictions Std       5341.3
trainer/Q2 Predictions Max      21413
trainer/Q2 Predictions Min       -181.745
trainer/Q Targets Mean           9944.63
trainer/Q Targets Std            5346.36
trainer/Q Targets Max           21097.3
trainer/Q Targets Min            -184.576
trainer/Bellman Errors 1 Mean  158819
trainer/Bellman Errors 1 Std        1.45689e+06
trainer/Bellman Errors 1 Max        2.32719e+07
trainer/Bellman Errors 1 Min        2.47068
trainer/Bellman Errors 2 Mean  157362
trainer/Bellman Errors 2 Std        1.48684e+06
trainer/Bellman Errors 2 Max        2.37891e+07
trainer/Bellman Errors 2 Min        1.37135
trainer/Policy Action Mean          0.67524
trainer/Policy Action Std           0.57041
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     50000
exploration/num paths total      1283
exploration/path length Mean      100
exploration/path length Std        14.7445
exploration/path length Max       110
exploration/path length Min        58
exploration/Rewards Mean            2.00397
exploration/Rewards Std             0.41792
exploration/Rewards Max             2.97539
exploration/Rewards Min             1.00782
exploration/Returns Mean          200.397
exploration/Returns Std            34.6639
exploration/Returns Max           224.914
exploration/Returns Min           100.869
exploration/Actions Mean            0.0927226
exploration/Actions Std             0.742223
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns       200.397
evaluation/num steps total     242786
evaluation/num paths total       6359
evaluation/path length Mean       102.417
evaluation/path length Std          3.37165
evaluation/path length Max        110
evaluation/path length Min         95
evaluation/Rewards Mean             2.01531
evaluation/Rewards Std              0.416078
evaluation/Rewards Max              3.01368
evaluation/Rewards Min              1.00591
evaluation/Returns Mean           206.401
evaluation/Returns Std              7.60485
evaluation/Returns Max            227.068
evaluation/Returns Min            191.371
evaluation/Actions Mean             0.0926064
evaluation/Actions Std              0.758078
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               48
evaluation/Average Returns        206.401
time/data storing (s)               0.00342203
time/evaluation sampling (s)        1.73514
time/exploration sampling (s)       0.366424
time/logging (s)                    0.0103269
time/saving (s)                     0.0034614
time/training (s)                   3.64917
time/epoch (s)                      5.76795
time/total (s)                    290.124
Epoch                              48
-----------------------------  ----------------
2021-07-02 23:33:38.272883 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 49 finished
-----------------------------  ----------------
replay_buffer/size              51000
trainer/QF1 Loss               124625
trainer/QF2 Loss               130207
trainer/Policy Loss            -10974.8
trainer/Q1 Predictions Mean     10049.3
trainer/Q1 Predictions Std       5485.45
trainer/Q1 Predictions Max      20355.5
trainer/Q1 Predictions Min       -214.746
trainer/Q2 Predictions Mean     10063.2
trainer/Q2 Predictions Std       5494.87
trainer/Q2 Predictions Max      20451.7
trainer/Q2 Predictions Min       -225.447
trainer/Q Targets Mean          10063.5
trainer/Q Targets Std            5499.44
trainer/Q Targets Max           20662.4
trainer/Q Targets Min            -229.323
trainer/Bellman Errors 1 Mean  124625
trainer/Bellman Errors 1 Std   652252
trainer/Bellman Errors 1 Max        6.64777e+06
trainer/Bellman Errors 1 Min        0.358361
trainer/Bellman Errors 2 Mean  130207
trainer/Bellman Errors 2 Std   769250
trainer/Bellman Errors 2 Max        8.98514e+06
trainer/Bellman Errors 2 Min        0.0362635
trainer/Policy Action Mean          0.673128
trainer/Policy Action Std           0.587869
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     51000
exploration/num paths total      1294
exploration/path length Mean       90.9091
exploration/path length Std        23.1966
exploration/path length Max       104
exploration/path length Min        18
exploration/Rewards Mean            1.95986
exploration/Rewards Std             0.412848
exploration/Rewards Max             2.86492
exploration/Rewards Min             1.0116
exploration/Returns Mean          178.169
exploration/Returns Std            47.3747
exploration/Returns Max           202.598
exploration/Returns Min            28.9287
exploration/Actions Mean            0.142135
exploration/Actions Std             0.725584
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              11
exploration/Average Returns       178.169
evaluation/num steps total     247695
evaluation/num paths total       6409
evaluation/path length Mean        98.18
evaluation/path length Std          1.79655
evaluation/path length Max        102
evaluation/path length Min         94
evaluation/Rewards Mean             1.96257
evaluation/Rewards Std              0.409063
evaluation/Rewards Max              2.86602
evaluation/Rewards Min              1.00782
evaluation/Returns Mean           192.685
evaluation/Returns Std              3.03909
evaluation/Returns Max            199.043
evaluation/Returns Min            185.176
evaluation/Actions Mean             0.142516
evaluation/Actions Std              0.734641
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               50
evaluation/Average Returns        192.685
time/data storing (s)               0.0035271
time/evaluation sampling (s)        1.74957
time/exploration sampling (s)       0.37217
time/logging (s)                    0.0101037
time/saving (s)                     0.00366258
time/training (s)                   3.65511
time/epoch (s)                      5.79415
time/total (s)                    295.921
Epoch                              49
-----------------------------  ----------------
2021-07-02 23:33:44.330853 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 50 finished
-----------------------------  ----------------
replay_buffer/size              52000
trainer/QF1 Loss               187802
trainer/QF2 Loss               185140
trainer/Policy Loss            -12118.1
trainer/Q1 Predictions Mean     11208.2
trainer/Q1 Predictions Std       5646.18
trainer/Q1 Predictions Max      19906.6
trainer/Q1 Predictions Min       -222.58
trainer/Q2 Predictions Mean     11218.5
trainer/Q2 Predictions Std       5640.29
trainer/Q2 Predictions Max      19881.6
trainer/Q2 Predictions Min       -303.498
trainer/Q Targets Mean          11163.4
trainer/Q Targets Std            5690.32
trainer/Q Targets Max           19930.3
trainer/Q Targets Min            -342.654
trainer/Bellman Errors 1 Mean  187802
trainer/Bellman Errors 1 Std        1.73126e+06
trainer/Bellman Errors 1 Max        2.76931e+07
trainer/Bellman Errors 1 Min        0.536621
trainer/Bellman Errors 2 Mean  185140
trainer/Bellman Errors 2 Std        1.71201e+06
trainer/Bellman Errors 2 Max        2.74146e+07
trainer/Bellman Errors 2 Min        0.506822
trainer/Policy Action Mean          0.654036
trainer/Policy Action Std           0.585805
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     52000
exploration/num paths total      1304
exploration/path length Mean      100
exploration/path length Std        22.3562
exploration/path length Max       109
exploration/path length Min        33
exploration/Rewards Mean            2.00882
exploration/Rewards Std             0.41583
exploration/Rewards Max             2.93567
exploration/Rewards Min             1.00764
exploration/Returns Mean          200.882
exploration/Returns Std            48.4605
exploration/Returns Max           220.961
exploration/Returns Min            55.7003
exploration/Actions Mean            0.119573
exploration/Actions Std             0.715582
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              10
exploration/Average Returns       200.882
evaluation/num steps total     252649
evaluation/num paths total       6455
evaluation/path length Mean       107.696
evaluation/path length Std          1.42752
evaluation/path length Max        110
evaluation/path length Min        104
evaluation/Rewards Mean             2.01993
evaluation/Rewards Std              0.409806
evaluation/Rewards Max              2.89495
evaluation/Rewards Min              1.00663
evaluation/Returns Mean           217.538
evaluation/Returns Std              2.83033
evaluation/Returns Max            222.822
evaluation/Returns Min            211.274
evaluation/Actions Mean             0.113894
evaluation/Actions Std              0.721487
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               46
evaluation/Average Returns        217.538
time/data storing (s)               0.00346608
time/evaluation sampling (s)        1.8476
time/exploration sampling (s)       0.36877
time/logging (s)                    0.00994947
time/saving (s)                     0.00353498
time/training (s)                   3.8211
time/epoch (s)                      6.05442
time/total (s)                    301.978
Epoch                              50
-----------------------------  ----------------
2021-07-02 23:33:50.170897 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 51 finished
-----------------------------  ----------------
replay_buffer/size              53000
trainer/QF1 Loss               613734
trainer/QF2 Loss               589808
trainer/Policy Loss            -12159.7
trainer/Q1 Predictions Mean     11430.5
trainer/Q1 Predictions Std       6406.55
trainer/Q1 Predictions Max      19322.6
trainer/Q1 Predictions Min       -585.082
trainer/Q2 Predictions Mean     11443.6
trainer/Q2 Predictions Std       6407.66
trainer/Q2 Predictions Max      19327.6
trainer/Q2 Predictions Min       -318.609
trainer/Q Targets Mean          11369.7
trainer/Q Targets Std            6424.64
trainer/Q Targets Max           19393.3
trainer/Q Targets Min            -280.797
trainer/Bellman Errors 1 Mean  613734
trainer/Bellman Errors 1 Std        8.58016e+06
trainer/Bellman Errors 1 Max        1.37599e+08
trainer/Bellman Errors 1 Min        0.603427
trainer/Bellman Errors 2 Mean  589808
trainer/Bellman Errors 2 Std        8.31146e+06
trainer/Bellman Errors 2 Max        1.33288e+08
trainer/Bellman Errors 2 Min        0.145164
trainer/Policy Action Mean          0.60576
trainer/Policy Action Std           0.631427
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     53000
exploration/num paths total      1315
exploration/path length Mean       90.9091
exploration/path length Std        17.391
exploration/path length Max        98
exploration/path length Min        36
exploration/Rewards Mean            2.03437
exploration/Rewards Std             0.484519
exploration/Rewards Max             3.07193
exploration/Rewards Min             1.00811
exploration/Returns Mean          184.943
exploration/Returns Std            39.7249
exploration/Returns Max           201.422
exploration/Returns Min            59.5318
exploration/Actions Mean            0.207068
exploration/Actions Std             0.741856
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              11
exploration/Average Returns       184.943
evaluation/num steps total     257560
evaluation/num paths total       6506
evaluation/path length Mean        96.2941
evaluation/path length Std          1.72972
evaluation/path length Max        100
evaluation/path length Min         92
evaluation/Rewards Mean             2.05598
evaluation/Rewards Std              0.498432
evaluation/Rewards Max              3.13177
evaluation/Rewards Min              1.00942
evaluation/Returns Mean           197.979
evaluation/Returns Std              3.68981
evaluation/Returns Max            206.112
evaluation/Returns Min            188.506
evaluation/Actions Mean             0.200332
evaluation/Actions Std              0.762901
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               51
evaluation/Average Returns        197.979
time/data storing (s)               0.00344651
time/evaluation sampling (s)        1.80358
time/exploration sampling (s)       0.368357
time/logging (s)                    0.00986291
time/saving (s)                     0.00368677
time/training (s)                   3.64797
time/epoch (s)                      5.8369
time/total (s)                    307.817
Epoch                              51
-----------------------------  ----------------
2021-07-02 23:33:55.987086 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 52 finished
-----------------------------  ----------------
replay_buffer/size              54000
trainer/QF1 Loss                76838.4
trainer/QF2 Loss                78090.7
trainer/Policy Loss            -13135.3
trainer/Q1 Predictions Mean     12470.1
trainer/Q1 Predictions Std       6273.51
trainer/Q1 Predictions Max      19385.4
trainer/Q1 Predictions Min       -406.096
trainer/Q2 Predictions Mean     12437.4
trainer/Q2 Predictions Std       6261.93
trainer/Q2 Predictions Max      19415.2
trainer/Q2 Predictions Min       -293.001
trainer/Q Targets Mean          12462.4
trainer/Q Targets Std            6282.37
trainer/Q Targets Max           19332.1
trainer/Q Targets Min            -380.097
trainer/Bellman Errors 1 Mean   76838.4
trainer/Bellman Errors 1 Std   211699
trainer/Bellman Errors 1 Max        2.74626e+06
trainer/Bellman Errors 1 Min        0.968874
trainer/Bellman Errors 2 Mean   78090.7
trainer/Bellman Errors 2 Std   167204
trainer/Bellman Errors 2 Max        1.75012e+06
trainer/Bellman Errors 2 Min        0.156595
trainer/Policy Action Mean          0.525189
trainer/Policy Action Std           0.665666
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     54000
exploration/num paths total      1329
exploration/path length Mean       71.4286
exploration/path length Std         7.01747
exploration/path length Max        79
exploration/path length Min        47
exploration/Rewards Mean            1.75783
exploration/Rewards Std             0.31219
exploration/Rewards Max             2.53177
exploration/Rewards Min             1.00895
exploration/Returns Mean          125.559
exploration/Returns Std            13.3446
exploration/Returns Max           141.001
exploration/Returns Min            79.512
exploration/Actions Mean            0.182397
exploration/Actions Std             0.735047
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              14
exploration/Average Returns       125.559
evaluation/num steps total     262512
evaluation/num paths total       6569
evaluation/path length Mean        78.6032
evaluation/path length Std         13.1361
evaluation/path length Max        128
evaluation/path length Min         70
evaluation/Rewards Mean             1.78712
evaluation/Rewards Std              0.321913
evaluation/Rewards Max              2.7664
evaluation/Rewards Min              1.00965
evaluation/Returns Mean           140.474
evaluation/Returns Std             28.3191
evaluation/Returns Max            250.429
evaluation/Returns Min            121.192
evaluation/Actions Mean             0.173249
evaluation/Actions Std              0.743675
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               63
evaluation/Average Returns        140.474
time/data storing (s)               0.00345451
time/evaluation sampling (s)        1.81251
time/exploration sampling (s)       0.365238
time/logging (s)                    0.0100164
time/saving (s)                     0.00362204
time/training (s)                   3.61855
time/epoch (s)                      5.81339
time/total (s)                    313.633
Epoch                              52
-----------------------------  ----------------
2021-07-02 23:34:01.742998 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 53 finished
-----------------------------  ----------------
replay_buffer/size              55000
trainer/QF1 Loss               185434
trainer/QF2 Loss               189959
trainer/Policy Loss            -12063.3
trainer/Q1 Predictions Mean     11589.3
trainer/Q1 Predictions Std       6524.5
trainer/Q1 Predictions Max      18142.5
trainer/Q1 Predictions Min       -169.188
trainer/Q2 Predictions Mean     11578.8
trainer/Q2 Predictions Std       6530.7
trainer/Q2 Predictions Max      18326.4
trainer/Q2 Predictions Min       -135.433
trainer/Q Targets Mean          11578.5
trainer/Q Targets Std            6555.65
trainer/Q Targets Max           18247.7
trainer/Q Targets Min             -95.8971
trainer/Bellman Errors 1 Mean  185434
trainer/Bellman Errors 1 Std        1.89587e+06
trainer/Bellman Errors 1 Max        3.0343e+07
trainer/Bellman Errors 1 Min        1.48535
trainer/Bellman Errors 2 Mean  189959
trainer/Bellman Errors 2 Std        1.85979e+06
trainer/Bellman Errors 2 Max        2.9743e+07
trainer/Bellman Errors 2 Min        0.314213
trainer/Policy Action Mean          0.49679
trainer/Policy Action Std           0.694968
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     55000
exploration/num paths total      1344
exploration/path length Mean       66.6667
exploration/path length Std         6.99206
exploration/path length Max        70
exploration/path length Min        41
exploration/Rewards Mean            1.70121
exploration/Rewards Std             0.309893
exploration/Rewards Max             2.81623
exploration/Rewards Min             1.00454
exploration/Returns Mean          113.414
exploration/Returns Std            12.4554
exploration/Returns Max           121.09
exploration/Returns Min            68.7413
exploration/Actions Mean            0.280573
exploration/Actions Std             0.746065
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              15
exploration/Average Returns       113.414
evaluation/num steps total     267445
evaluation/num paths total       6641
evaluation/path length Mean        68.5139
evaluation/path length Std          0.799185
evaluation/path length Max         71
evaluation/path length Min         68
evaluation/Rewards Mean             1.70067
evaluation/Rewards Std              0.303147
evaluation/Rewards Max              2.90507
evaluation/Rewards Min              1.00902
evaluation/Returns Mean           116.519
evaluation/Returns Std              2.62407
evaluation/Returns Max            124.727
evaluation/Returns Min            113.38
evaluation/Actions Mean             0.285511
evaluation/Actions Std              0.765442
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               72
evaluation/Average Returns        116.519
time/data storing (s)               0.00343351
time/evaluation sampling (s)        1.76195
time/exploration sampling (s)       0.370991
time/logging (s)                    0.00998093
time/saving (s)                     0.00350867
time/training (s)                   3.60297
time/epoch (s)                      5.75283
time/total (s)                    319.389
Epoch                              53
-----------------------------  ----------------
2021-07-02 23:34:07.492324 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 54 finished
-----------------------------  ----------------
replay_buffer/size              56000
trainer/QF1 Loss                72470.4
trainer/QF2 Loss                69072.7
trainer/Policy Loss            -13541.3
trainer/Q1 Predictions Mean     12946.1
trainer/Q1 Predictions Std       5623.08
trainer/Q1 Predictions Max      18216.2
trainer/Q1 Predictions Min        -72.8736
trainer/Q2 Predictions Mean     12955.5
trainer/Q2 Predictions Std       5609.09
trainer/Q2 Predictions Max      18513.8
trainer/Q2 Predictions Min        -61.1769
trainer/Q Targets Mean          12934.4
trainer/Q Targets Std            5634.78
trainer/Q Targets Max           18353.7
trainer/Q Targets Min             -48.1384
trainer/Bellman Errors 1 Mean   72470.4
trainer/Bellman Errors 1 Std   220454
trainer/Bellman Errors 1 Max        2.13294e+06
trainer/Bellman Errors 1 Min        0.0272379
trainer/Bellman Errors 2 Mean   69072.7
trainer/Bellman Errors 2 Std   222380
trainer/Bellman Errors 2 Max        2.23529e+06
trainer/Bellman Errors 2 Min        0.0220337
trainer/Policy Action Mean          0.358509
trainer/Policy Action Std           0.732562
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     56000
exploration/num paths total      1358
exploration/path length Mean       71.4286
exploration/path length Std        19.8088
exploration/path length Max       107
exploration/path length Min        11
exploration/Rewards Mean            1.67119
exploration/Rewards Std             0.44038
exploration/Rewards Max             3.61578
exploration/Rewards Min             0.141441
exploration/Returns Mean          119.371
exploration/Returns Std            38.4973
exploration/Returns Max           199.494
exploration/Returns Min            14.6561
exploration/Actions Mean            0.242612
exploration/Actions Std             0.779041
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              14
exploration/Average Returns       119.371
evaluation/num steps total     272439
evaluation/num paths total       6706
evaluation/path length Mean        76.8308
evaluation/path length Std          7.77485
evaluation/path length Max        108
evaluation/path length Min         64
evaluation/Rewards Mean             1.79326
evaluation/Rewards Std              0.44006
evaluation/Rewards Max              3.96296
evaluation/Rewards Min              0.970878
evaluation/Returns Mean           137.778
evaluation/Returns Std             21.1315
evaluation/Returns Max            217.72
evaluation/Returns Min            106.639
evaluation/Actions Mean             0.266638
evaluation/Actions Std              0.785296
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               65
evaluation/Average Returns        137.778
time/data storing (s)               0.00339682
time/evaluation sampling (s)        1.75117
time/exploration sampling (s)       0.368357
time/logging (s)                    0.0100825
time/saving (s)                     0.00372293
time/training (s)                   3.60965
time/epoch (s)                      5.74638
time/total (s)                    325.138
Epoch                              54
-----------------------------  ----------------
2021-07-02 23:34:13.337866 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 55 finished
-----------------------------  ----------------
replay_buffer/size              57000
trainer/QF1 Loss                75378
trainer/QF2 Loss                89078
trainer/Policy Loss            -12185.9
trainer/Q1 Predictions Mean     11710.7
trainer/Q1 Predictions Std       6000.29
trainer/Q1 Predictions Max      17910.2
trainer/Q1 Predictions Min       -381.274
trainer/Q2 Predictions Mean     11721.1
trainer/Q2 Predictions Std       5997.04
trainer/Q2 Predictions Max      17775.9
trainer/Q2 Predictions Min       -158.711
trainer/Q Targets Mean          11707
trainer/Q Targets Std            6023.92
trainer/Q Targets Max           18385
trainer/Q Targets Min            -268.116
trainer/Bellman Errors 1 Mean   75378
trainer/Bellman Errors 1 Std   169859
trainer/Bellman Errors 1 Max        1.21798e+06
trainer/Bellman Errors 1 Min        0.565881
trainer/Bellman Errors 2 Mean   89078
trainer/Bellman Errors 2 Std   258038
trainer/Bellman Errors 2 Max        2.70588e+06
trainer/Bellman Errors 2 Min        0.742839
trainer/Policy Action Mean          0.182089
trainer/Policy Action Std           0.764074
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     57000
exploration/num paths total      1374
exploration/path length Mean       62.5
exploration/path length Std         2
exploration/path length Max        66
exploration/path length Min        59
exploration/Rewards Mean            0.442802
exploration/Rewards Std             0.236665
exploration/Rewards Max             1.02525
exploration/Rewards Min            -0.084929
exploration/Returns Mean           27.6751
exploration/Returns Std             2.65314
exploration/Returns Max            31.8436
exploration/Returns Min            23.1214
exploration/Actions Mean            0.452328
exploration/Actions Std             0.557845
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths              16
exploration/Average Returns        27.6751
evaluation/num steps total     277380
evaluation/num paths total       6785
evaluation/path length Mean        62.5443
evaluation/path length Std          1.30041
evaluation/path length Max         65
evaluation/path length Min         60
evaluation/Rewards Mean             0.441703
evaluation/Rewards Std              0.234351
evaluation/Rewards Max              1.031
evaluation/Rewards Min             -0.0900471
evaluation/Returns Mean            27.626
evaluation/Returns Std              1.84525
evaluation/Returns Max             31.5428
evaluation/Returns Min             23.6012
evaluation/Actions Mean             0.468827
evaluation/Actions Std              0.544538
evaluation/Actions Max              1
evaluation/Actions Min             -0.998513
evaluation/Num Paths               79
evaluation/Average Returns         27.626
time/data storing (s)               0.00344821
time/evaluation sampling (s)        1.82512
time/exploration sampling (s)       0.37834
time/logging (s)                    0.00999531
time/saving (s)                     0.00345251
time/training (s)                   3.62197
time/epoch (s)                      5.84233
time/total (s)                    330.982
Epoch                              55
-----------------------------  ----------------
2021-07-02 23:34:19.197230 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 56 finished
-----------------------------  ----------------
replay_buffer/size              58000
trainer/QF1 Loss               121556
trainer/QF2 Loss               114091
trainer/Policy Loss            -11731
trainer/Q1 Predictions Mean     11035.7
trainer/Q1 Predictions Std       5981.82
trainer/Q1 Predictions Max      17499.5
trainer/Q1 Predictions Min        -86.6999
trainer/Q2 Predictions Mean     11047.3
trainer/Q2 Predictions Std       5968.29
trainer/Q2 Predictions Max      17446.7
trainer/Q2 Predictions Min        -73.417
trainer/Q Targets Mean          11073.2
trainer/Q Targets Std            5934.73
trainer/Q Targets Max           17186.4
trainer/Q Targets Min            -154.571
trainer/Bellman Errors 1 Mean  121556
trainer/Bellman Errors 1 Std   693876
trainer/Bellman Errors 1 Max        1.03676e+07
trainer/Bellman Errors 1 Min        0.106388
trainer/Bellman Errors 2 Mean  114091
trainer/Bellman Errors 2 Std   651267
trainer/Bellman Errors 2 Max        9.78191e+06
trainer/Bellman Errors 2 Min        1.81092
trainer/Policy Action Mean          0.0867933
trainer/Policy Action Std           0.758876
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     58000
exploration/num paths total      1375
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.974899
exploration/Rewards Std             0.0998341
exploration/Rewards Max             1.04847
exploration/Rewards Min             0.244732
exploration/Returns Mean          974.899
exploration/Returns Std             0
exploration/Returns Max           974.899
exploration/Returns Min           974.899
exploration/Actions Mean            0.362491
exploration/Actions Std             0.321418
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       974.899
evaluation/num steps total     282380
evaluation/num paths total       6790
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.97505
evaluation/Rewards Std              0.0928571
evaluation/Rewards Max              1.03289
evaluation/Rewards Min              0.294335
evaluation/Returns Mean           975.05
evaluation/Returns Std              0.38016
evaluation/Returns Max            975.422
evaluation/Returns Min            974.332
evaluation/Actions Mean             0.357909
evaluation/Actions Std              0.29834
evaluation/Actions Max              0.997986
evaluation/Actions Min             -0.967477
evaluation/Num Paths                5
evaluation/Average Returns        975.05
time/data storing (s)               0.00343468
time/evaluation sampling (s)        1.82509
time/exploration sampling (s)       0.382947
time/logging (s)                    0.00989186
time/saving (s)                     0.00478779
time/training (s)                   3.63008
time/epoch (s)                      5.85623
time/total (s)                    336.841
Epoch                              56
-----------------------------  ----------------
2021-07-02 23:34:25.027444 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 57 finished
-----------------------------  ---------------
replay_buffer/size              59000
trainer/QF1 Loss                43177.8
trainer/QF2 Loss                40219.9
trainer/Policy Loss            -11827.3
trainer/Q1 Predictions Mean     11352
trainer/Q1 Predictions Std       5808.72
trainer/Q1 Predictions Max      16759.5
trainer/Q1 Predictions Min       -206.315
trainer/Q2 Predictions Mean     11345.8
trainer/Q2 Predictions Std       5797.25
trainer/Q2 Predictions Max      16715.2
trainer/Q2 Predictions Min       -113.886
trainer/Q Targets Mean          11369.7
trainer/Q Targets Std            5814.74
trainer/Q Targets Max           16941.2
trainer/Q Targets Min             -70.0175
trainer/Bellman Errors 1 Mean   43177.8
trainer/Bellman Errors 1 Std    91317.3
trainer/Bellman Errors 1 Max   750668
trainer/Bellman Errors 1 Min        0.522232
trainer/Bellman Errors 2 Mean   40219.9
trainer/Bellman Errors 2 Std    87006.4
trainer/Bellman Errors 2 Max   821208
trainer/Bellman Errors 2 Min        0.250529
trainer/Policy Action Mean          0.0908039
trainer/Policy Action Std           0.77594
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     59000
exploration/num paths total      1376
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.975319
exploration/Rewards Std             0.0835715
exploration/Rewards Max             1.06732
exploration/Rewards Min             0.444949
exploration/Returns Mean          975.319
exploration/Returns Std             0
exploration/Returns Max           975.319
exploration/Returns Min           975.319
exploration/Actions Mean            0.356671
exploration/Actions Std             0.391842
exploration/Actions Max             1
exploration/Actions Min            -0.935051
exploration/Num Paths               1
exploration/Average Returns       975.319
evaluation/num steps total     287380
evaluation/num paths total       6795
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.976161
evaluation/Rewards Std              0.0799286
evaluation/Rewards Max              1.04435
evaluation/Rewards Min              0.466899
evaluation/Returns Mean           976.161
evaluation/Returns Std              0.53556
evaluation/Returns Max            976.966
evaluation/Returns Min            975.584
evaluation/Actions Mean             0.345837
evaluation/Actions Std              0.376728
evaluation/Actions Max              0.981272
evaluation/Actions Min             -0.999033
evaluation/Num Paths                5
evaluation/Average Returns        976.161
time/data storing (s)               0.00346536
time/evaluation sampling (s)        1.81753
time/exploration sampling (s)       0.384557
time/logging (s)                    0.009726
time/saving (s)                     0.00353102
time/training (s)                   3.60755
time/epoch (s)                      5.82635
time/total (s)                    342.671
Epoch                              57
-----------------------------  ---------------
2021-07-02 23:34:30.956872 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 58 finished
-----------------------------  ----------------
replay_buffer/size              60000
trainer/QF1 Loss                55009.7
trainer/QF2 Loss                57006.1
trainer/Policy Loss            -11230.5
trainer/Q1 Predictions Mean     10533.2
trainer/Q1 Predictions Std       6009.87
trainer/Q1 Predictions Max      16865.8
trainer/Q1 Predictions Min        -94.7371
trainer/Q2 Predictions Mean     10521.4
trainer/Q2 Predictions Std       5998.97
trainer/Q2 Predictions Max      16696
trainer/Q2 Predictions Min        -50.2801
trainer/Q Targets Mean          10574.1
trainer/Q Targets Std            6013.23
trainer/Q Targets Max           16730.7
trainer/Q Targets Min             -89.8387
trainer/Bellman Errors 1 Mean   55009.7
trainer/Bellman Errors 1 Std   121646
trainer/Bellman Errors 1 Max   984721
trainer/Bellman Errors 1 Min        0.00624077
trainer/Bellman Errors 2 Mean   57006.1
trainer/Bellman Errors 2 Std   139341
trainer/Bellman Errors 2 Max        1.17654e+06
trainer/Bellman Errors 2 Min        0.0417271
trainer/Policy Action Mean          0.157245
trainer/Policy Action Std           0.776648
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     60000
exploration/num paths total      1377
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.97965
exploration/Rewards Std             0.0723555
exploration/Rewards Max             1.04845
exploration/Rewards Min             0.514506
exploration/Returns Mean          979.65
exploration/Returns Std             0
exploration/Returns Max           979.65
exploration/Returns Min           979.65
exploration/Actions Mean            0.447287
exploration/Actions Std             0.373824
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       979.65
evaluation/num steps total     292380
evaluation/num paths total       6800
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.980309
evaluation/Rewards Std              0.06989
evaluation/Rewards Max              1.03197
evaluation/Rewards Min              0.444558
evaluation/Returns Mean           980.309
evaluation/Returns Std              0.252146
evaluation/Returns Max            980.751
evaluation/Returns Min            980.042
evaluation/Actions Mean             0.478769
evaluation/Actions Std              0.354765
evaluation/Actions Max              0.999843
evaluation/Actions Min             -0.979252
evaluation/Num Paths                5
evaluation/Average Returns        980.309
time/data storing (s)               0.00361279
time/evaluation sampling (s)        1.85539
time/exploration sampling (s)       0.395735
time/logging (s)                    0.00992161
time/saving (s)                     0.00369438
time/training (s)                   3.65795
time/epoch (s)                      5.92631
time/total (s)                    348.6
Epoch                              58
-----------------------------  ----------------
2021-07-02 23:34:36.906299 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 59 finished
-----------------------------  ----------------
replay_buffer/size              61000
trainer/QF1 Loss                45303.3
trainer/QF2 Loss                43854.1
trainer/Policy Loss            -11288.4
trainer/Q1 Predictions Mean     10775.5
trainer/Q1 Predictions Std       5715.6
trainer/Q1 Predictions Max      16770.5
trainer/Q1 Predictions Min        -48.0955
trainer/Q2 Predictions Mean     10780.6
trainer/Q2 Predictions Std       5723.74
trainer/Q2 Predictions Max      16756.1
trainer/Q2 Predictions Min        -71.5303
trainer/Q Targets Mean          10808.4
trainer/Q Targets Std            5711.24
trainer/Q Targets Max           16800.9
trainer/Q Targets Min             -48.8338
trainer/Bellman Errors 1 Mean   45303.3
trainer/Bellman Errors 1 Std   105470
trainer/Bellman Errors 1 Max   851145
trainer/Bellman Errors 1 Min        1.3396
trainer/Bellman Errors 2 Mean   43854.1
trainer/Bellman Errors 2 Std   130617
trainer/Bellman Errors 2 Max        1.46876e+06
trainer/Bellman Errors 2 Min        0.0250282
trainer/Policy Action Mean          0.137682
trainer/Policy Action Std           0.789313
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     61000
exploration/num paths total      1378
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.980613
exploration/Rewards Std             0.0694067
exploration/Rewards Max             1.06349
exploration/Rewards Min             0.540975
exploration/Returns Mean          980.613
exploration/Returns Std             0
exploration/Returns Max           980.613
exploration/Returns Min           980.613
exploration/Actions Mean            0.400385
exploration/Actions Std             0.356161
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       980.613
evaluation/num steps total     297380
evaluation/num paths total       6805
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.980804
evaluation/Rewards Std              0.0653679
evaluation/Rewards Max              1.00503
evaluation/Rewards Min              0.457567
evaluation/Returns Mean           980.804
evaluation/Returns Std              0.182176
evaluation/Returns Max            981.051
evaluation/Returns Min            980.506
evaluation/Actions Mean             0.425933
evaluation/Actions Std              0.325647
evaluation/Actions Max              0.99771
evaluation/Actions Min             -0.999906
evaluation/Num Paths                5
evaluation/Average Returns        980.804
time/data storing (s)               0.00339293
time/evaluation sampling (s)        1.89806
time/exploration sampling (s)       0.385494
time/logging (s)                    0.0100072
time/saving (s)                     0.00364471
time/training (s)                   3.64559
time/epoch (s)                      5.94618
time/total (s)                    354.549
Epoch                              59
-----------------------------  ----------------
2021-07-02 23:34:42.797486 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 60 finished
-----------------------------  ---------------
replay_buffer/size              62000
trainer/QF1 Loss                29198.5
trainer/QF2 Loss                32332.9
trainer/Policy Loss            -11176.6
trainer/Q1 Predictions Mean     10660.8
trainer/Q1 Predictions Std       5558.13
trainer/Q1 Predictions Max      16662.7
trainer/Q1 Predictions Min        -22.7327
trainer/Q2 Predictions Mean     10621.9
trainer/Q2 Predictions Std       5549.14
trainer/Q2 Predictions Max      16228.8
trainer/Q2 Predictions Min        -37.0719
trainer/Q Targets Mean          10670.5
trainer/Q Targets Std            5572.15
trainer/Q Targets Max           16309.2
trainer/Q Targets Min             -15.6658
trainer/Bellman Errors 1 Mean   29198.5
trainer/Bellman Errors 1 Std    50319.3
trainer/Bellman Errors 1 Max   389151
trainer/Bellman Errors 1 Min        0.010216
trainer/Bellman Errors 2 Mean   32332.9
trainer/Bellman Errors 2 Std    61824.6
trainer/Bellman Errors 2 Max   606290
trainer/Bellman Errors 2 Min        0.01445
trainer/Policy Action Mean          0.184935
trainer/Policy Action Std           0.80303
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     62000
exploration/num paths total      1379
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.978615
exploration/Rewards Std             0.0707619
exploration/Rewards Max             1.01925
exploration/Rewards Min             0.543887
exploration/Returns Mean          978.615
exploration/Returns Std             0
exploration/Returns Max           978.615
exploration/Returns Min           978.615
exploration/Actions Mean            0.393927
exploration/Actions Std             0.354327
exploration/Actions Max             1
exploration/Actions Min            -0.947497
exploration/Num Paths               1
exploration/Average Returns       978.615
evaluation/num steps total     302380
evaluation/num paths total       6810
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.980307
evaluation/Rewards Std              0.066809
evaluation/Rewards Max              0.999221
evaluation/Rewards Min              0.530779
evaluation/Returns Mean           980.307
evaluation/Returns Std              0.810214
evaluation/Returns Max            981.235
evaluation/Returns Min            978.947
evaluation/Actions Mean             0.404898
evaluation/Actions Std              0.302926
evaluation/Actions Max              0.994747
evaluation/Actions Min             -0.999904
evaluation/Num Paths                5
evaluation/Average Returns        980.307
time/data storing (s)               0.00338058
time/evaluation sampling (s)        1.83034
time/exploration sampling (s)       0.386835
time/logging (s)                    0.0100737
time/saving (s)                     0.00353846
time/training (s)                   3.65374
time/epoch (s)                      5.88791
time/total (s)                    360.439
Epoch                              60
-----------------------------  ---------------
2021-07-02 23:34:48.662364 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 61 finished
-----------------------------  ----------------
replay_buffer/size              63000
trainer/QF1 Loss               231778
trainer/QF2 Loss               228298
trainer/Policy Loss            -10198.5
trainer/Q1 Predictions Mean      9816.2
trainer/Q1 Predictions Std       5624.06
trainer/Q1 Predictions Max      16182.3
trainer/Q1 Predictions Min       -279.04
trainer/Q2 Predictions Mean      9838.43
trainer/Q2 Predictions Std       5621.84
trainer/Q2 Predictions Max      16049.8
trainer/Q2 Predictions Min       -210.352
trainer/Q Targets Mean           9811.8
trainer/Q Targets Std            5654.21
trainer/Q Targets Max           16188.2
trainer/Q Targets Min             -99.4759
trainer/Bellman Errors 1 Mean  231778
trainer/Bellman Errors 1 Std        3.16935e+06
trainer/Bellman Errors 1 Max        5.08002e+07
trainer/Bellman Errors 1 Min        0.122739
trainer/Bellman Errors 2 Mean  228298
trainer/Bellman Errors 2 Std        3.04212e+06
trainer/Bellman Errors 2 Max        4.87543e+07
trainer/Bellman Errors 2 Min        0.0217149
trainer/Policy Action Mean          0.229171
trainer/Policy Action Std           0.796116
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     63000
exploration/num paths total      1380
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.980661
exploration/Rewards Std             0.0667637
exploration/Rewards Max             1.02606
exploration/Rewards Min             0.560725
exploration/Returns Mean          980.661
exploration/Returns Std             0
exploration/Returns Max           980.661
exploration/Returns Min           980.661
exploration/Actions Mean            0.443009
exploration/Actions Std             0.368433
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       980.661
evaluation/num steps total     307380
evaluation/num paths total       6815
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.981418
evaluation/Rewards Std              0.0651154
evaluation/Rewards Max              0.999101
evaluation/Rewards Min              0.575998
evaluation/Returns Mean           981.418
evaluation/Returns Std              0.576199
evaluation/Returns Max            982.082
evaluation/Returns Min            980.579
evaluation/Actions Mean             0.445068
evaluation/Actions Std              0.32086
evaluation/Actions Max              0.998547
evaluation/Actions Min             -0.99999
evaluation/Num Paths                5
evaluation/Average Returns        981.418
time/data storing (s)               0.00338218
time/evaluation sampling (s)        1.84105
time/exploration sampling (s)       0.382522
time/logging (s)                    0.010169
time/saving (s)                     0.00368491
time/training (s)                   3.62046
time/epoch (s)                      5.86127
time/total (s)                    366.304
Epoch                              61
-----------------------------  ----------------
2021-07-02 23:34:54.583552 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 62 finished
-----------------------------  ----------------
replay_buffer/size              64000
trainer/QF1 Loss                54475.9
trainer/QF2 Loss                53919.6
trainer/Policy Loss            -10906.8
trainer/Q1 Predictions Mean     10371.8
trainer/Q1 Predictions Std       5259.08
trainer/Q1 Predictions Max      15743.2
trainer/Q1 Predictions Min        -69.911
trainer/Q2 Predictions Mean     10379.6
trainer/Q2 Predictions Std       5255.26
trainer/Q2 Predictions Max      15828
trainer/Q2 Predictions Min       -101.347
trainer/Q Targets Mean          10402.8
trainer/Q Targets Std            5296.42
trainer/Q Targets Max           15780.9
trainer/Q Targets Min             -91.3364
trainer/Bellman Errors 1 Mean   54475.9
trainer/Bellman Errors 1 Std   234044
trainer/Bellman Errors 1 Max        3.53905e+06
trainer/Bellman Errors 1 Min        0.293305
trainer/Bellman Errors 2 Mean   53919.6
trainer/Bellman Errors 2 Std   242136
trainer/Bellman Errors 2 Max        3.64053e+06
trainer/Bellman Errors 2 Min        0.0374174
trainer/Policy Action Mean          0.312705
trainer/Policy Action Std           0.826643
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     64000
exploration/num paths total      1381
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.983009
exploration/Rewards Std             0.0646968
exploration/Rewards Max             1.05673
exploration/Rewards Min             0.595473
exploration/Returns Mean          983.009
exploration/Returns Std             0
exploration/Returns Max           983.009
exploration/Returns Min           983.009
exploration/Actions Mean            0.577307
exploration/Actions Std             0.499879
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       983.009
evaluation/num steps total     312380
evaluation/num paths total       6820
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.982434
evaluation/Rewards Std              0.0667419
evaluation/Rewards Max              1.04355
evaluation/Rewards Min              0.566857
evaluation/Returns Mean           982.434
evaluation/Returns Std              0.506657
evaluation/Returns Max            983.024
evaluation/Returns Min            981.529
evaluation/Actions Mean             0.575466
evaluation/Actions Std              0.51886
evaluation/Actions Max              0.996317
evaluation/Actions Min             -0.991093
evaluation/Num Paths                5
evaluation/Average Returns        982.434
time/data storing (s)               0.00341422
time/evaluation sampling (s)        1.86377
time/exploration sampling (s)       0.387143
time/logging (s)                    0.0108547
time/saving (s)                     0.00360594
time/training (s)                   3.6494
time/epoch (s)                      5.91819
time/total (s)                    372.225
Epoch                              62
-----------------------------  ----------------
2021-07-02 23:35:00.592834 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 63 finished
-----------------------------  ----------------
replay_buffer/size              65000
trainer/QF1 Loss                35445.2
trainer/QF2 Loss                44171.1
trainer/Policy Loss            -10618.7
trainer/Q1 Predictions Mean     10149.2
trainer/Q1 Predictions Std       5326.09
trainer/Q1 Predictions Max      15667.4
trainer/Q1 Predictions Min        -53.3299
trainer/Q2 Predictions Mean     10156.7
trainer/Q2 Predictions Std       5328.11
trainer/Q2 Predictions Max      15557.3
trainer/Q2 Predictions Min        -45.9623
trainer/Q Targets Mean          10158
trainer/Q Targets Std            5320.61
trainer/Q Targets Max           15458.6
trainer/Q Targets Min             -54.1487
trainer/Bellman Errors 1 Mean   35445.2
trainer/Bellman Errors 1 Std    96764
trainer/Bellman Errors 1 Max        1.04567e+06
trainer/Bellman Errors 1 Min        0.347916
trainer/Bellman Errors 2 Mean   44171.1
trainer/Bellman Errors 2 Std   105468
trainer/Bellman Errors 2 Max   826251
trainer/Bellman Errors 2 Min        0.0176392
trainer/Policy Action Mean          0.408882
trainer/Policy Action Std           0.790147
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     65000
exploration/num paths total      1382
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.988714
exploration/Rewards Std             0.046747
exploration/Rewards Max             1.02623
exploration/Rewards Min             0.567593
exploration/Returns Mean          988.714
exploration/Returns Std             0
exploration/Returns Max           988.714
exploration/Returns Min           988.714
exploration/Actions Mean            0.58887
exploration/Actions Std             0.452266
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       988.714
evaluation/num steps total     317380
evaluation/num paths total       6825
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.98876
evaluation/Rewards Std              0.0455822
evaluation/Rewards Max              1.05462
evaluation/Rewards Min              0.488331
evaluation/Returns Mean           988.76
evaluation/Returns Std              0.670247
evaluation/Returns Max            989.729
evaluation/Returns Min            987.808
evaluation/Actions Mean             0.602542
evaluation/Actions Std              0.439811
evaluation/Actions Max              0.999412
evaluation/Actions Min             -1
evaluation/Num Paths                5
evaluation/Average Returns        988.76
time/data storing (s)               0.0034794
time/evaluation sampling (s)        1.90099
time/exploration sampling (s)       0.406158
time/logging (s)                    0.010013
time/saving (s)                     0.00358962
time/training (s)                   3.68046
time/epoch (s)                      6.00469
time/total (s)                    378.233
Epoch                              63
-----------------------------  ----------------
2021-07-02 23:35:06.577906 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 64 finished
-----------------------------  ---------------
replay_buffer/size              66000
trainer/QF1 Loss                34735
trainer/QF2 Loss                35126.7
trainer/Policy Loss            -10869.8
trainer/Q1 Predictions Mean     10339.9
trainer/Q1 Predictions Std       5091.22
trainer/Q1 Predictions Max      15222.8
trainer/Q1 Predictions Min       -109.832
trainer/Q2 Predictions Mean     10335
trainer/Q2 Predictions Std       5084.29
trainer/Q2 Predictions Max      15315.8
trainer/Q2 Predictions Min        -98.7973
trainer/Q Targets Mean          10316.1
trainer/Q Targets Std            5067.4
trainer/Q Targets Max           15193.7
trainer/Q Targets Min            -133.619
trainer/Bellman Errors 1 Mean   34735.1
trainer/Bellman Errors 1 Std    65703.3
trainer/Bellman Errors 1 Max   423764
trainer/Bellman Errors 1 Min        0.0322645
trainer/Bellman Errors 2 Mean   35126.7
trainer/Bellman Errors 2 Std    75894.1
trainer/Bellman Errors 2 Max   749148
trainer/Bellman Errors 2 Min        0.14279
trainer/Policy Action Mean          0.344868
trainer/Policy Action Std           0.813002
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     66000
exploration/num paths total      1383
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.984969
exploration/Rewards Std             0.0665098
exploration/Rewards Max             1.14559
exploration/Rewards Min             0.548435
exploration/Returns Mean          984.969
exploration/Returns Std             0
exploration/Returns Max           984.969
exploration/Returns Min           984.969
exploration/Actions Mean            0.452216
exploration/Actions Std             0.616137
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       984.969
evaluation/num steps total     322380
evaluation/num paths total       6830
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.985599
evaluation/Rewards Std              0.0608683
evaluation/Rewards Max              1.12055
evaluation/Rewards Min              0.508389
evaluation/Returns Mean           985.599
evaluation/Returns Std              0.861702
evaluation/Returns Max            987.097
evaluation/Returns Min            984.56
evaluation/Actions Mean             0.476134
evaluation/Actions Std              0.620963
evaluation/Actions Max              0.999986
evaluation/Actions Min             -1
evaluation/Num Paths                5
evaluation/Average Returns        985.599
time/data storing (s)               0.00341693
time/evaluation sampling (s)        1.97563
time/exploration sampling (s)       0.379506
time/logging (s)                    0.0101749
time/saving (s)                     0.00350836
time/training (s)                   3.60911
time/epoch (s)                      5.98135
time/total (s)                    384.218
Epoch                              64
-----------------------------  ---------------
2021-07-02 23:35:12.411861 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 65 finished
-----------------------------  ----------------
replay_buffer/size              67000
trainer/QF1 Loss                48293.4
trainer/QF2 Loss                43986.7
trainer/Policy Loss            -10573.3
trainer/Q1 Predictions Mean      9994.46
trainer/Q1 Predictions Std       4897.17
trainer/Q1 Predictions Max      14688.1
trainer/Q1 Predictions Min        -52.4816
trainer/Q2 Predictions Mean      9996.02
trainer/Q2 Predictions Std       4886.48
trainer/Q2 Predictions Max      14641.2
trainer/Q2 Predictions Min       -114.179
trainer/Q Targets Mean           9977.22
trainer/Q Targets Std            4897.21
trainer/Q Targets Max           14777.5
trainer/Q Targets Min             -39.5579
trainer/Bellman Errors 1 Mean   48293.4
trainer/Bellman Errors 1 Std   170294
trainer/Bellman Errors 1 Max        2.02651e+06
trainer/Bellman Errors 1 Min        0.0446767
trainer/Bellman Errors 2 Mean   43986.7
trainer/Bellman Errors 2 Std   162250
trainer/Bellman Errors 2 Max        2.05755e+06
trainer/Bellman Errors 2 Min        0.155655
trainer/Policy Action Mean          0.453185
trainer/Policy Action Std           0.73852
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     67000
exploration/num paths total      1384
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.99563
exploration/Rewards Std             0.112014
exploration/Rewards Max             1.30064
exploration/Rewards Min             0.663095
exploration/Returns Mean          995.63
exploration/Returns Std             0
exploration/Returns Max           995.63
exploration/Returns Min           995.63
exploration/Actions Mean            0.214974
exploration/Actions Std             0.655343
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       995.63
evaluation/num steps total     327380
evaluation/num paths total       6835
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.99352
evaluation/Rewards Std              0.10406
evaluation/Rewards Max              1.31964
evaluation/Rewards Min              0.601586
evaluation/Returns Mean           993.52
evaluation/Returns Std              1.16795
evaluation/Returns Max            995.626
evaluation/Returns Min            992.165
evaluation/Actions Mean             0.232123
evaluation/Actions Std              0.65664
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths                5
evaluation/Average Returns        993.52
time/data storing (s)               0.00343205
time/evaluation sampling (s)        1.8369
time/exploration sampling (s)       0.378587
time/logging (s)                    0.0104829
time/saving (s)                     0.00354359
time/training (s)                   3.59794
time/epoch (s)                      5.83088
time/total (s)                    390.051
Epoch                              65
-----------------------------  ----------------
2021-07-02 23:35:18.302974 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 66 finished
-----------------------------  ----------------
replay_buffer/size              68000
trainer/QF1 Loss                41227.1
trainer/QF2 Loss                33814.6
trainer/Policy Loss            -10105.8
trainer/Q1 Predictions Mean      9560.25
trainer/Q1 Predictions Std       4785.04
trainer/Q1 Predictions Max      14216.2
trainer/Q1 Predictions Min        -54.6305
trainer/Q2 Predictions Mean      9555.73
trainer/Q2 Predictions Std       4770.69
trainer/Q2 Predictions Max      14305.3
trainer/Q2 Predictions Min        -91.5924
trainer/Q Targets Mean           9533
trainer/Q Targets Std            4752.71
trainer/Q Targets Max           14161.9
trainer/Q Targets Min             -52.0556
trainer/Bellman Errors 1 Mean   41227.1
trainer/Bellman Errors 1 Std   150395
trainer/Bellman Errors 1 Max        1.97748e+06
trainer/Bellman Errors 1 Min        0.197977
trainer/Bellman Errors 2 Mean   33814.6
trainer/Bellman Errors 2 Std    96041.9
trainer/Bellman Errors 2 Max        1.05984e+06
trainer/Bellman Errors 2 Min        0.649095
trainer/Policy Action Mean          0.293929
trainer/Policy Action Std           0.761455
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     68000
exploration/num paths total      1385
exploration/path length Mean     1000
exploration/path length Std         0
exploration/path length Max      1000
exploration/path length Min      1000
exploration/Rewards Mean            0.998181
exploration/Rewards Std             0.0659885
exploration/Rewards Max             1.22695
exploration/Rewards Min             0.584508
exploration/Returns Mean          998.181
exploration/Returns Std             0
exploration/Returns Max           998.181
exploration/Returns Min           998.181
exploration/Actions Mean            0.135664
exploration/Actions Std             0.5719
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               1
exploration/Average Returns       998.181
evaluation/num steps total     332380
evaluation/num paths total       6840
evaluation/path length Mean      1000
evaluation/path length Std          0
evaluation/path length Max       1000
evaluation/path length Min       1000
evaluation/Rewards Mean             0.998839
evaluation/Rewards Std              0.0595671
evaluation/Rewards Max              1.21462
evaluation/Rewards Min              0.588397
evaluation/Returns Mean           998.839
evaluation/Returns Std              0.67549
evaluation/Returns Max            999.53
evaluation/Returns Min            997.573
evaluation/Actions Mean             0.135257
evaluation/Actions Std              0.561938
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths                5
evaluation/Average Returns        998.839
time/data storing (s)               0.00339364
time/evaluation sampling (s)        1.852
time/exploration sampling (s)       0.380201
time/logging (s)                    0.00987521
time/saving (s)                     0.00354769
time/training (s)                   3.63798
time/epoch (s)                      5.887
time/total (s)                    395.941
Epoch                              66
-----------------------------  ----------------
2021-07-02 23:35:24.217087 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 67 finished
-----------------------------  ----------------
replay_buffer/size              69000
trainer/QF1 Loss                34566.6
trainer/QF2 Loss                32360.6
trainer/Policy Loss            -10343.4
trainer/Q1 Predictions Mean      9859.87
trainer/Q1 Predictions Std       4518.92
trainer/Q1 Predictions Max      13896.2
trainer/Q1 Predictions Min        -40.998
trainer/Q2 Predictions Mean      9871.84
trainer/Q2 Predictions Std       4529.7
trainer/Q2 Predictions Max      13809.2
trainer/Q2 Predictions Min        -41.7683
trainer/Q Targets Mean           9854.5
trainer/Q Targets Std            4511.16
trainer/Q Targets Max           13997.2
trainer/Q Targets Min             -43.9595
trainer/Bellman Errors 1 Mean   34566.6
trainer/Bellman Errors 1 Std   106193
trainer/Bellman Errors 1 Max        1.30384e+06
trainer/Bellman Errors 1 Min        0.042057
trainer/Bellman Errors 2 Mean   32360.6
trainer/Bellman Errors 2 Std    79682.6
trainer/Bellman Errors 2 Max   704268
trainer/Bellman Errors 2 Min        0.684244
trainer/Policy Action Mean          0.352145
trainer/Policy Action Std           0.725473
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     69000
exploration/num paths total      1388
exploration/path length Mean      333.333
exploration/path length Std        33.9837
exploration/path length Max       373
exploration/path length Min       290
exploration/Rewards Mean            1.28522
exploration/Rewards Std             0.165957
exploration/Rewards Max             1.6697
exploration/Rewards Min             0.573566
exploration/Returns Mean          428.406
exploration/Returns Std            46.8944
exploration/Returns Max           477.401
exploration/Returns Min           365.201
exploration/Actions Mean            0.0579102
exploration/Actions Std             0.566044
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               3
exploration/Average Returns       428.406
evaluation/num steps total     337356
evaluation/num paths total       6854
evaluation/path length Mean       355.429
evaluation/path length Std         14.0393
evaluation/path length Max        381
evaluation/path length Min        331
evaluation/Rewards Mean             1.28904
evaluation/Rewards Std              0.168131
evaluation/Rewards Max              1.62442
evaluation/Rewards Min              0.58244
evaluation/Returns Mean           458.16
evaluation/Returns Std             14.4283
evaluation/Returns Max            484.274
evaluation/Returns Min            432.26
evaluation/Actions Mean             0.0514912
evaluation/Actions Std              0.595426
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               14
evaluation/Average Returns        458.16
time/data storing (s)               0.00346154
time/evaluation sampling (s)        1.84767
time/exploration sampling (s)       0.390853
time/logging (s)                    0.0118968
time/saving (s)                     0.00380291
time/training (s)                   3.65507
time/epoch (s)                      5.91276
time/total (s)                    401.857
Epoch                              67
-----------------------------  ----------------
2021-07-02 23:35:30.062003 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 68 finished
-----------------------------  ---------------
replay_buffer/size              70000
trainer/QF1 Loss                23545.5
trainer/QF2 Loss                25934.4
trainer/Policy Loss            -10173.4
trainer/Q1 Predictions Mean      9747.85
trainer/Q1 Predictions Std       4376.11
trainer/Q1 Predictions Max      13788.4
trainer/Q1 Predictions Min        -35.9774
trainer/Q2 Predictions Mean      9743.64
trainer/Q2 Predictions Std       4376.32
trainer/Q2 Predictions Max      13805.9
trainer/Q2 Predictions Min        -40.2835
trainer/Q Targets Mean           9755.98
trainer/Q Targets Std            4391.33
trainer/Q Targets Max           13910.5
trainer/Q Targets Min             -58.3356
trainer/Bellman Errors 1 Mean   23545.5
trainer/Bellman Errors 1 Std    44554
trainer/Bellman Errors 1 Max   331597
trainer/Bellman Errors 1 Min        0.118164
trainer/Bellman Errors 2 Mean   25934.4
trainer/Bellman Errors 2 Std    59973.3
trainer/Bellman Errors 2 Max   662482
trainer/Bellman Errors 2 Min        0.0353281
trainer/Policy Action Mean          0.432069
trainer/Policy Action Std           0.677648
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     70000
exploration/num paths total      1392
exploration/path length Mean      250
exploration/path length Std       109.181
exploration/path length Max       316
exploration/path length Min        61
exploration/Rewards Mean            1.37723
exploration/Rewards Std             0.216018
exploration/Rewards Max             1.96731
exploration/Rewards Min             0.664067
exploration/Returns Mean          344.307
exploration/Returns Std           157.378
exploration/Returns Max           440.241
exploration/Returns Min            71.9013
exploration/Actions Mean            0.101632
exploration/Actions Std             0.557356
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               4
exploration/Average Returns       344.307
evaluation/num steps total     342174
evaluation/num paths total       6869
evaluation/path length Mean       321.2
evaluation/path length Std          9.2246
evaluation/path length Max        348
evaluation/path length Min        306
evaluation/Rewards Mean             1.37996
evaluation/Rewards Std              0.218967
evaluation/Rewards Max              2.0378
evaluation/Rewards Min              0.536282
evaluation/Returns Mean           443.244
evaluation/Returns Std              9.50334
evaluation/Returns Max            469.7
evaluation/Returns Min            427.691
evaluation/Actions Mean             0.0997286
evaluation/Actions Std              0.550417
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               15
evaluation/Average Returns        443.244
time/data storing (s)               0.00343309
time/evaluation sampling (s)        1.82347
time/exploration sampling (s)       0.375924
time/logging (s)                    0.0103104
time/saving (s)                     0.0036748
time/training (s)                   3.62214
time/epoch (s)                      5.83895
time/total (s)                    407.7
Epoch                              68
-----------------------------  ---------------
2021-07-02 23:35:35.926075 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 69 finished
-----------------------------  ----------------
replay_buffer/size              71000
trainer/QF1 Loss                50251.1
trainer/QF2 Loss                52059.5
trainer/Policy Loss             -9745.6
trainer/Q1 Predictions Mean      9283.78
trainer/Q1 Predictions Std       4137.53
trainer/Q1 Predictions Max      13154.9
trainer/Q1 Predictions Min        -45.837
trainer/Q2 Predictions Mean      9284.4
trainer/Q2 Predictions Std       4141.37
trainer/Q2 Predictions Max      13297.8
trainer/Q2 Predictions Min        -42.5389
trainer/Q Targets Mean           9302.93
trainer/Q Targets Std            4175.11
trainer/Q Targets Max           13296.6
trainer/Q Targets Min             -39.5428
trainer/Bellman Errors 1 Mean   50251.1
trainer/Bellman Errors 1 Std   223968
trainer/Bellman Errors 1 Max        3.01114e+06
trainer/Bellman Errors 1 Min        0.566816
trainer/Bellman Errors 2 Mean   52059.5
trainer/Bellman Errors 2 Std   236383
trainer/Bellman Errors 2 Max        3.09133e+06
trainer/Bellman Errors 2 Min        0.142831
trainer/Policy Action Mean          0.272358
trainer/Policy Action Std           0.744141
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     71000
exploration/num paths total      1395
exploration/path length Mean      333.333
exploration/path length Std        55.259
exploration/path length Max       386
exploration/path length Min       257
exploration/Rewards Mean            1.29903
exploration/Rewards Std             0.214726
exploration/Rewards Max             1.94037
exploration/Rewards Min             0.556126
exploration/Returns Mean          433.011
exploration/Returns Std            81.2012
exploration/Returns Max           499.8
exploration/Returns Min           318.717
exploration/Actions Mean            0.0559958
exploration/Actions Std             0.534097
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               3
exploration/Average Returns       433.011
evaluation/num steps total     347034
evaluation/num paths total       6882
evaluation/path length Mean       373.846
evaluation/path length Std         12.2778
evaluation/path length Max        397
evaluation/path length Min        355
evaluation/Rewards Mean             1.31196
evaluation/Rewards Std              0.206243
evaluation/Rewards Max              1.86865
evaluation/Rewards Min              0.498996
evaluation/Returns Mean           490.47
evaluation/Returns Std             12.5486
evaluation/Returns Max            512.758
evaluation/Returns Min            472.195
evaluation/Actions Mean             0.0429517
evaluation/Actions Std              0.536798
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               13
evaluation/Average Returns        490.47
time/data storing (s)               0.00342726
time/evaluation sampling (s)        1.8277
time/exploration sampling (s)       0.375799
time/logging (s)                    0.0095781
time/saving (s)                     0.0035164
time/training (s)                   3.63905
time/epoch (s)                      5.85907
time/total (s)                    413.562
Epoch                              69
-----------------------------  ----------------
2021-07-02 23:35:41.843271 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 70 finished
-----------------------------  ----------------
replay_buffer/size              72000
trainer/QF1 Loss                31044.6
trainer/QF2 Loss                40237.8
trainer/Policy Loss            -10031.7
trainer/Q1 Predictions Mean      9558.89
trainer/Q1 Predictions Std       4090.4
trainer/Q1 Predictions Max      13346.2
trainer/Q1 Predictions Min        -13.1636
trainer/Q2 Predictions Mean      9542.74
trainer/Q2 Predictions Std       4083.35
trainer/Q2 Predictions Max      13355.5
trainer/Q2 Predictions Min        -10.5714
trainer/Q Targets Mean           9532.54
trainer/Q Targets Std            4086.16
trainer/Q Targets Max           13018.6
trainer/Q Targets Min              -0.908405
trainer/Bellman Errors 1 Mean   31044.6
trainer/Bellman Errors 1 Std   100918
trainer/Bellman Errors 1 Max        1.32028e+06
trainer/Bellman Errors 1 Min        0.0226173
trainer/Bellman Errors 2 Mean   40237.8
trainer/Bellman Errors 2 Std   147377
trainer/Bellman Errors 2 Max        1.78705e+06
trainer/Bellman Errors 2 Min        0.00267887
trainer/Policy Action Mean          0.33793
trainer/Policy Action Std           0.723688
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     72000
exploration/num paths total      1398
exploration/path length Mean      333.333
exploration/path length Std       220.442
exploration/path length Max       503
exploration/path length Min        22
exploration/Rewards Mean            1.26014
exploration/Rewards Std             0.235813
exploration/Rewards Max             2.02067
exploration/Rewards Min             0.550434
exploration/Returns Mean          420.046
exploration/Returns Std           282.649
exploration/Returns Max           635.938
exploration/Returns Min            20.7599
exploration/Actions Mean            0.0888957
exploration/Actions Std             0.507257
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               3
exploration/Average Returns       420.046
evaluation/num steps total     351917
evaluation/num paths total       6892
evaluation/path length Mean       488.3
evaluation/path length Std         16.6436
evaluation/path length Max        514
evaluation/path length Min        459
evaluation/Rewards Mean             1.25375
evaluation/Rewards Std              0.208134
evaluation/Rewards Max              1.88514
evaluation/Rewards Min              0.542471
evaluation/Returns Mean           612.204
evaluation/Returns Std             16.7731
evaluation/Returns Max            639.245
evaluation/Returns Min            583.26
evaluation/Actions Mean             0.0704342
evaluation/Actions Std              0.456764
evaluation/Actions Max              1
evaluation/Actions Min             -1
evaluation/Num Paths               10
evaluation/Average Returns        612.204
time/data storing (s)               0.00341891
time/evaluation sampling (s)        1.86058
time/exploration sampling (s)       0.385652
time/logging (s)                    0.0123359
time/saving (s)                     0.00366758
time/training (s)                   3.65118
time/epoch (s)                      5.91683
time/total (s)                    419.481
Epoch                              70
-----------------------------  ----------------
2021-07-02 23:35:47.742633 CST | [rlkit-post-refactor-td3-hopper-env_2021_07_02_23_28_42_0000--s-0] Epoch 71 finished
-----------------------------  ---------------
replay_buffer/size              73000
trainer/QF1 Loss                19360.6
trainer/QF2 Loss                20810.6
trainer/Policy Loss             -9519.14
trainer/Q1 Predictions Mean      9108.01
trainer/Q1 Predictions Std       4305.75
trainer/Q1 Predictions Max      12823.5
trainer/Q1 Predictions Min         -8.659
trainer/Q2 Predictions Mean      9132.67
trainer/Q2 Predictions Std       4307.37
trainer/Q2 Predictions Max      12779.4
trainer/Q2 Predictions Min         -3.30116
trainer/Q Targets Mean           9127.75
trainer/Q Targets Std            4317.7
trainer/Q Targets Max           12759.6
trainer/Q Targets Min              -4.42749
trainer/Bellman Errors 1 Mean   19360.6
trainer/Bellman Errors 1 Std    38235.5
trainer/Bellman Errors 1 Max   281341
trainer/Bellman Errors 1 Min        0.298238
trainer/Bellman Errors 2 Mean   20810.6
trainer/Bellman Errors 2 Std    44140.7
trainer/Bellman Errors 2 Max   369545
trainer/Bellman Errors 2 Min        0.00241701
trainer/Policy Action Mean          0.355822
trainer/Policy Action Std           0.691035
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     73000
exploration/num paths total      1400
exploration/path length Mean      500
exploration/path length Std        83
exploration/path length Max       583
exploration/path length Min       417
exploration/Rewards Mean            1.19619
exploration/Rewards Std             0.216391
exploration/Rewards Max             2.13892
exploration/Rewards Min             0.4606
exploration/Returns Mean          598.097
exploration/Returns Std           126.085
exploration/Returns Max           724.182
exploration/Returns Min           472.012
exploration/Actions Mean            0.0918377
exploration/Actions Std             0.477693
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       598.097
evaluation/num steps total     356812
evaluation/num paths total       6900
evaluation/path length Mean       611.875
evaluation/path length Std         14.6836
evaluation/path length Max        632
evaluation/path length Min        589
evaluation/Rewards Mean             1.22297
evaluation/Rewards Std              0.233307
evaluation/Rewards Max              2.0363
evaluation/Rewards Min              0.558014
evaluation/Returns Mean           748.302
evaluation/Returns Std             14.6788
evaluation/Returns Max            769.079
evaluation/Returns Min            724.392
evaluation/Actions Mean             0.0787862
evaluation/Actions Std              0.483688
evaluation/Actions Max              0.999996
evaluation/Actions Min             -0.999966
evaluation/Num Paths                8
evaluation/Average Returns        748.302
time/data storing (s)               0.00338334
time/evaluation sampling (s)        1.83641
time/exploration sampling (s)       0.379634
time/logging (s)                    0.00982132
time/saving (s)                     0.00367354
time/training (s)                   3.65997
time/epoch (s)                      5.89289
time/total (s)                    425.377
Epoch                              71
-----------------------------  ---------------
